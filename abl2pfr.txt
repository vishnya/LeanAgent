(base) yingzi_ma@cais-login-0:~/lean_project/ReProver$ srun --partition=compute --gpus=4 --nodes=1 --time=2-00
:00:00 --pty /bin/bash
srun: job 42045 queued and waiting for resources
srun: job 42045 has been allocated resources
(base) yingzi_ma@compute-permanent-node-1021:~/lean_project/ReProver$ bash run_code3_abl2.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
Stopping ray
Did not find any active Ray processes.
kill: (6943): Operation not permitted
kill: (7223): Operation not permitted
kill: (1754216): Operation not permitted
kill: (1754655): Operation not permitted
kill: (1754857): Operation not permitted
kill: (1755011): Operation not permitted
kill: (1796073): Operation not permitted
kill: (1796174): Operation not permitted
kill: (1796298): No such process
kill: (1969173): Operation not permitted
kill: (1969210): Operation not permitted
kill: (1969211): Operation not permitted
kill: (1969212): Operation not permitted
kill: (1969219): Operation not permitted
kill: (1970479): Operation not permitted
kill: (1970522): Operation not permitted
kill: (1970523): Operation not permitted
kill: (1970524): Operation not permitted
kill: (1970531): Operation not permitted
kill: (1971213): Operation not permitted
kill: (1971231): Operation not permitted
kill: (1971232): Operation not permitted
kill: (1971233): Operation not permitted
kill: (1971240): Operation not permitted
Sun Sep 22 18:15:17 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:0F:00.0 Off |                    0 |
| N/A   54C    P0             97W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:15:00.0 Off |                    0 |
| N/A   38C    P0             86W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   56C    P0            101W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   54C    P0            103W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running main3_abl2.py
[2024-09-22 18:15:26,226] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (aut
o detect)
2024-09-22 18:15:31.651 | INFO     | __main__:main:1402 - Running progressive training
2024-09-22 18:15:31.651 | INFO     | __main__:main:1408 - Configuring LeanDojo...
2024-09-22 18:15:31.654 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directo
ry: /data/yingzi_ma/lean_project/ReProver
2024-09-22 18:15:31.654 | INFO     | __main__:main:1410 - LeanDojo configured
2024-09-22 18:15:31.654 | INFO     | __main__:main:1415 - Starting the main process
2024-09-22 18:15:31.654 | INFO     | __main__:main:1423 - Loading database from /data/yingzi_ma/lean_project/d
ynamic_database_PT_single_repo_no_ewc_curriculum_abl2.json
2024-09-22 18:16:30.835 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/lecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-22 18:16:30.835 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/lecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-22 18:16:38.126 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/ImperialCollegeLondon/FLT (commit: b208a302cdcbfadce33d8165f0b054bfa17e2147)
2024-09-22 18:16:38.127 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/ImperialCollegeLondon/FLT (commit: b208a302cdcbfadce33d8165f0b054bfa17e2147)
2024-09-22 18:16:39.984 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/teorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-22 18:16:39.985 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/teorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-22 18:16:48.430 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 89bf7b5e3a226525e8580bae21ef543604f99b21)
2024-09-22 18:16:48.431 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 89bf7b5e3a226525e8580bae21ef543604f99b21)
2024-09-22 18:16:59.156 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/dwrensha/compfiles (commit: f99bf6f2928d47dd1a445b414b3a723c2665f091)
2024-09-22 18:16:59.156 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/dwrensha/compfiles (commit: f99bf6f2928d47dd1a445b414b3a723c2665f091)
2024-09-22 18:17:09.100 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/google-deepmind/debate (commit: 7fb39251b705797ee54e08c96177fabd29a5b5a3)
2024-09-22 18:17:09.100 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/google-deepmind/debate (commit: 7fb39251b705797ee54e08c96177fabd29a5b5a3)
2024-09-22 18:17:11.117 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-22 18:17:11.117 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-22 18:17:11.735 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/FormalizedFormalLogic/Foundation (commit: d5fe5d057a90a0703a745cdc318a1b6621490c21)
2024-09-22 18:17:11.735 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/FormalizedFormalLogic/Foundation (commit: d5fe5d057a90a0703a745cdc318a1b6621490c21)
2024-09-22 18:17:11.879 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/digama0/lean4lean (commit: 05b1f4a68c5facea96a5ee51c6a56fef21276e0f)
2024-09-22 18:17:11.879 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/digama0/lean4lean (commit: 05b1f4a68c5facea96a5ee51c6a56fef21276e0f)
2024-09-22 18:17:23.083 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/eric-wieser/lean-matrix-cookbook (commit: f15a149d321ac99ff9b9c024b58e7882f564669f)
2024-09-22 18:17:23.083 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/eric-wieser/lean-matrix-cookbook (commit: f15a149d321ac99ff9b9c024b58e7882f564669f)
2024-09-22 18:17:24.987 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/yuma-mizuno/lean-math-workshop (commit: 5acd4b933d47fd6c1032798a6046c1baf261445d)
2024-09-22 18:17:24.987 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/yuma-mizuno/lean-math-workshop (commit: 5acd4b933d47fd6c1032798a6046c1baf261445d)
2024-09-22 18:17:25.351 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/loganrjmurphy/LeanEuclid (commit: f1912c3090eb82820575758efc31e40b9db86bb8)
2024-09-22 18:17:25.351 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/loganrjmurphy/LeanEuclid (commit: f1912c3090eb82820575758efc31e40b9db86bb8)
2024-09-22 18:17:26.081 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/leanprover-community/con-nf (commit: 00bdc85ba7d486a9e544a0806a1018dd06fa3856)
2024-09-22 18:17:26.081 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/leanprover-community/con-nf (commit: 00bdc85ba7d486a9e544a0806a1018dd06fa3856)
2024-09-22 18:17:26.375 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/siddhartha-gadgil/Saturn (commit: 3811a9dd46cdfd5fa0c0c1896720c28d2ec4a42a)
2024-09-22 18:17:26.376 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/siddhartha-gadgil/Saturn (commit: 3811a9dd46cdfd5fa0c0c1896720c28d2ec4a42a)
2024-09-22 18:17:39.729 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 29baddd685660b5fedd7bd67f9916ae24253d566)
2024-09-22 18:17:39.730 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 29baddd685660b5fedd7bd67f9916ae24253d566)
2024-09-22 18:17:41.023 | INFO     | __main__:main:1425 - Loaded database from /data/yingzi_ma/lean_project/dy
namic_database_PT_single_repo_no_ewc_curriculum_abl2.json
2024-09-22 18:17:41.024 | INFO     | __main__:main:1432 - Found 9 repositories
2024-09-22 18:17:41.024 | INFO     | __main__:main:1435 - Starting curriculum learning
2024-09-22 18:17:41.393 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc1
2024-09-22 18:17:58.655 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0
2024-09-22 18:18:16.086 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0
2024-09-22 18:18:34.293 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0-rc2
2024-09-22 18:18:51.916 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc2
2024-09-22 18:19:08.819 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:19:08.820 | INFO     | __main__:main:1520 - i: 0
2024-09-22 18:19:08.820 | INFO     | __main__:main:1526 - Main process
2024-09-22 18:19:08.820 | INFO     | __main__:main:1527 - Using lambda = 0.1
2024-09-22 18:19:08.820 | INFO     | __main__:main:1528 - Processing https://github.com/teorth/pfr
2024-09-22 18:19:08.820 | INFO     | __main__:main:1535 - Adding repo to repos_for_merged_dataset
2024-09-22 18:19:08.820 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:19:08.821 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b70579
7ee54e08c96177fabd29a5b5a3_lambda_0.1_epoch=6-Recall@10_val=67.33.ckpt
2024-09-22 18:19:08.821 | INFO     | __main__:main:1555 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b705797ee54e08c96177fabd29a
5b5a3_lambda_0.1_epoch=6-Recall@10_val=67.33.ckpt
2024-09-22 18:19:08.821 | INFO     | __main__:main:1561 - Inside train_test_fisher
2024-09-22 18:19:08.821 | INFO     | __main__:main:1562 - Starting training at epoch 4
[rank: 0] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:5
7: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pi
ckle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code du
ring unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more detail
s). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the funct
ions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via th
is mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We reco
mmend you start setting `weights_only=True` for any use case where you don't have full control of the loaded f
ile. Please open an issue on GitHub for any issues related to this experimental feature.
2024-09-22 18:19:11.931 | INFO     | __main__:main:1586 - Loaded premise retriever at /data/yingzi_ma/lean_pro
ject/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b705797ee54e08c96177fabd
29a5b5a3_lambda_0.1_epoch=6-Recall@10_val=67.33.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/sl
urm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run
Lightning on SLURM, prepend your python command with `srun` like so: srun python main3_abl2.py ...
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
2024-09-22 18:19:12.070 | INFO     | __main__:main:1644 - right before barrier for data module
2024-09-22 18:19:12.070 | INFO     | __main__:main:1659 - Data path: /data/yingzi_ma/lean_project/datasets_PT_
single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:
1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This beh
avior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details ch
eck this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-22 18:19:12.178 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687
/corpus.jsonl
2024-09-22 18:19:19.299 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_train/cached_data.pkl
Training dataset size: 169493
2024-09-22 18:19:19.315 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_val/cached_data.pkl
Validation dataset size: 2745
2024-09-22 18:19:19.329 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_pred/cached_data.pkl
Testing dataset size: 2597
2024-09-22 18:19:19.329 | INFO     | __main__:main:1673 - Training dataset size after load: 169493
2024-09-22 18:19:19.330 | INFO     | __main__:main:1674 - Validation dataset size after load: 2745
2024-09-22 18:19:19.330 | INFO     | __main__:main:1675 - Testing dataset size after load: 2597
2024-09-22 18:19:19.330 | INFO     | __main__:main:1677 - Starting progressive training from epoch 4 to 5
2024-09-22 18:19:19.330 | INFO     | __main__:main:1680 - hit the barrier before training
[rank: 0] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
[2024-09-22 18:19:25,482] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (aut
o detect)
[2024-09-22 18:19:25,485] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (aut
o detect)
[2024-09-22 18:19:25,485] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (aut
o detect)
2024-09-22 18:19:29.343 | INFO     | __main__:main:1402 - Running progressive training
2024-09-22 18:19:29.344 | INFO     | __main__:main:1408 - Configuring LeanDojo...
2024-09-22 18:19:29.347 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directo
ry: /data/yingzi_ma/lean_project/ReProver
2024-09-22 18:19:29.347 | INFO     | __main__:main:1410 - LeanDojo configured
2024-09-22 18:19:29.347 | INFO     | __main__:main:1432 - Found 9 repositories
2024-09-22 18:19:29.347 | INFO     | __main__:main:1435 - Starting curriculum learning
2024-09-22 18:19:29.348 | INFO     | __main__:main:1402 - Running progressive training
2024-09-22 18:19:29.348 | INFO     | __main__:main:1408 - Configuring LeanDojo...
2024-09-22 18:19:29.353 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directo
ry: /data/yingzi_ma/lean_project/ReProver
2024-09-22 18:19:29.353 | INFO     | __main__:main:1410 - LeanDojo configured
2024-09-22 18:19:29.353 | INFO     | __main__:main:1432 - Found 9 repositories
2024-09-22 18:19:29.353 | INFO     | __main__:main:1435 - Starting curriculum learning
2024-09-22 18:19:29.400 | INFO     | __main__:main:1402 - Running progressive training
2024-09-22 18:19:29.400 | INFO     | __main__:main:1408 - Configuring LeanDojo...
2024-09-22 18:19:29.403 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directo
ry: /data/yingzi_ma/lean_project/ReProver
2024-09-22 18:19:29.403 | INFO     | __main__:main:1410 - LeanDojo configured
2024-09-22 18:19:29.403 | INFO     | __main__:main:1432 - Found 9 repositories
2024-09-22 18:19:29.403 | INFO     | __main__:main:1435 - Starting curriculum learning
2024-09-22 18:19:29.529 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc1
2024-09-22 18:19:29.547 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc1
2024-09-22 18:19:29.607 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc1
2024-09-22 18:19:46.596 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0
2024-09-22 18:19:46.684 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0
2024-09-22 18:19:46.986 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0
2024-09-22 18:20:03.733 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0
2024-09-22 18:20:04.176 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0
2024-09-22 18:20:04.883 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0
2024-09-22 18:20:21.927 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0-rc2
2024-09-22 18:20:22.091 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0-rc2
2024-09-22 18:20:23.254 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0-rc2
2024-09-22 18:20:39.609 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc2
2024-09-22 18:20:39.858 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc2
2024-09-22 18:20:40.962 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc2
2024-09-22 18:20:57.084 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:20:57.084 | INFO     | __main__:main:1520 - i: 0
2024-09-22 18:20:57.084 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:20:57.086 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:20:57.086 | INFO     | __main__:main:1555 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:20:57.086 | INFO     | __main__:main:1561 - Inside train_test_fisher
2024-09-22 18:20:57.086 | INFO     | __main__:main:1562 - Starting training at epoch 4
[rank: 3] Seed set to 3407
2024-09-22 18:20:57.158 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:20:57.158 | INFO     | __main__:main:1520 - i: 0
2024-09-22 18:20:57.158 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:20:57.158 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:20:57.159 | INFO     | __main__:main:1555 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:20:57.159 | INFO     | __main__:main:1561 - Inside train_test_fisher
2024-09-22 18:20:57.159 | INFO     | __main__:main:1562 - Starting training at epoch 4
[rank: 1] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:5
7: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pi
ckle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code du
ring unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more detail
s). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the funct
ions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via th
is mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We reco
mmend you start setting `weights_only=True` for any use case where you don't have full control of the loaded f
ile. Please open an issue on GitHub for any issues related to this experimental feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:5
7: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pi
ckle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code du
ring unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more detail
s). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the funct
ions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via th
is mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We reco
mmend you start setting `weights_only=True` for any use case where you don't have full control of the loaded f
ile. Please open an issue on GitHub for any issues related to this experimental feature.
2024-09-22 18:20:58.084 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:20:58.084 | INFO     | __main__:main:1520 - i: 0
2024-09-22 18:20:58.084 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:20:58.085 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:20:58.085 | INFO     | __main__:main:1555 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:20:58.085 | INFO     | __main__:main:1561 - Inside train_test_fisher
2024-09-22 18:20:58.086 | INFO     | __main__:main:1562 - Starting training at epoch 4
[rank: 2] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:5
7: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pi
ckle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code du
ring unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more detail
s). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the funct
ions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via th
is mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We reco
mmend you start setting `weights_only=True` for any use case where you don't have full control of the loaded f
ile. Please open an issue on GitHub for any issues related to this experimental feature.
2024-09-22 18:21:00.351 | INFO     | __main__:main:1586 - Loaded premise retriever at /data/yingzi_ma/lean_pro
ject/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9
b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:00.456 | INFO     | __main__:main:1644 - right before barrier for data module
2024-09-22 18:21:00.456 | INFO     | __main__:main:1659 - Data path: /data/yingzi_ma/lean_project/datasets_PT_
single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687/random
2024-09-22 18:21:00.504 | INFO     | __main__:main:1586 - Loaded premise retriever at /data/yingzi_ma/lean_pro
ject/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9
b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:
1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This beh
avior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details ch
eck this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-22 18:21:00.553 | INFO     | __main__:main:1644 - right before barrier for data module
2024-09-22 18:21:00.554 | INFO     | __main__:main:1659 - Data path: /data/yingzi_ma/lean_project/datasets_PT_
single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687/random
2024-09-22 18:21:00.560 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687
/corpus.jsonl
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:
1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This beh
avior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details ch
eck this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-22 18:21:00.654 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687
/corpus.jsonl
2024-09-22 18:21:00.909 | INFO     | __main__:main:1586 - Loaded premise retriever at /data/yingzi_ma/lean_pro
ject/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9
b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:00.958 | INFO     | __main__:main:1644 - right before barrier for data module
2024-09-22 18:21:00.959 | INFO     | __main__:main:1659 - Data path: /data/yingzi_ma/lean_project/datasets_PT_
single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:
1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This beh
avior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details ch
eck this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-22 18:21:01.061 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687
/corpus.jsonl
2024-09-22 18:21:10.619 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_train/cached_data.pkl
Training dataset size: 169493
2024-09-22 18:21:10.636 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_val/cached_data.pkl
Validation dataset size: 2745
2024-09-22 18:21:10.652 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_pred/cached_data.pkl
Testing dataset size: 2597
2024-09-22 18:21:10.652 | INFO     | __main__:main:1673 - Training dataset size after load: 169493
2024-09-22 18:21:10.652 | INFO     | __main__:main:1674 - Validation dataset size after load: 2745
2024-09-22 18:21:10.652 | INFO     | __main__:main:1675 - Testing dataset size after load: 2597
2024-09-22 18:21:10.653 | INFO     | __main__:main:1677 - Starting progressive training from epoch 4 to 5
2024-09-22 18:21:10.653 | INFO     | __main__:main:1680 - hit the barrier before training
[rank: 3] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
2024-09-22 18:21:14.444 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_train/cached_data.pkl
Training dataset size: 169493
2024-09-22 18:21:14.461 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_val/cached_data.pkl
Validation dataset size: 2745
2024-09-22 18:21:14.476 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_pred/cached_data.pkl
Testing dataset size: 2597
2024-09-22 18:21:14.477 | INFO     | __main__:main:1673 - Training dataset size after load: 169493
2024-09-22 18:21:14.477 | INFO     | __main__:main:1674 - Validation dataset size after load: 2745
2024-09-22 18:21:14.477 | INFO     | __main__:main:1675 - Testing dataset size after load: 2597
2024-09-22 18:21:14.477 | INFO     | __main__:main:1677 - Starting progressive training from epoch 4 to 5
2024-09-22 18:21:14.477 | INFO     | __main__:main:1680 - hit the barrier before training
[rank: 1] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
2024-09-22 18:21:15.015 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_train/cached_data.pkl
Training dataset size: 169493
2024-09-22 18:21:15.029 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_val/cached_data.pkl
Validation dataset size: 2745
2024-09-22 18:21:15.041 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_pred/cached_data.pkl
Testing dataset size: 2597
2024-09-22 18:21:15.042 | INFO     | __main__:main:1673 - Training dataset size after load: 169493
2024-09-22 18:21:15.042 | INFO     | __main__:main:1674 - Validation dataset size after load: 2745
2024-09-22 18:21:15.042 | INFO     | __main__:main:1675 - Testing dataset size after load: 2597
2024-09-22 18:21:15.042 | INFO     | __main__:main:1677 - Starting progressive training from epoch 4 to 5
2024-09-22 18:21:15.042 | INFO     | __main__:main:1680 - hit the barrier before training
[rank: 2] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
2024-09-22 18:21:17.558 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_train/cached_data.pkl
Training dataset size: 169493
2024-09-22 18:21:17.694 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_val/cached_data.pkl
Validation dataset size: 2745
2024-09-22 18:21:17.721 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_pred/cached_data.pkl
Testing dataset size: 2597
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkp
oint.py:653: Checkpoint directory /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_ab
l2 exists and is not empty.
2024-09-22 18:21:19.950 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_train/cached_data.pkl
Training dataset size: 169493
2024-09-22 18:21:20.040 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_val/cached_data.pkl
Validation dataset size: 2745
2024-09-22 18:21:20.056 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_pred/cached_data.pkl
Testing dataset size: 2597
2024-09-22 18:21:20.182 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_train/cached_data.pkl
Training dataset size: 169493
2024-09-22 18:21:20.275 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_val/cached_data.pkl
Validation dataset size: 2745
2024-09-22 18:21:20.295 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_pred/cached_data.pkl
Testing dataset size: 2597
2024-09-22 18:21:21.158 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_train/cached_data.pkl
Training dataset size: 169493
2024-09-22 18:21:21.280 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_val/cached_data.pkl
Validation dataset size: 2745
2024-09-22 18:21:21.304 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e32
94c45e50c6aee013a2687/random/cache_pred/cached_data.pkl
Testing dataset size: 2597
Restoring states from the checkpoint path at /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_cu
rriculum_abl2/merged_with_new_debate_7fb39251b705797ee54e08c96177fabd29a5b5a3_lambda_0.1_epoch=6-Recall@10_val
=67.33.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:5
7: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pi
ckle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code du
ring unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more detail
s). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the funct
ions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via th
is mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We reco
mmend you start setting `weights_only=True` for any use case where you don't have full control of the loaded f
ile. Please open an issue on GitHub for any issues related to this experimental feature.
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
2024-09-22 18:21:22.747 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-22 18:21:22.747 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-22 18:21:22.749 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-22 18:21:22.749 | INFO     | common:get_optimizers:449 - Optimizing with AdamW

  | Name    | Type           | Params
-------------------------------------------
0 | encoder | T5EncoderModel | 217 M
-------------------------------------------
217 M     Trainable params
0         Non-trainable params
217 M     Total params
870.630   Total estimated model params size (MB)
An error occurred during training: You restored a checkpoint with current_epoch=7, but you have set Trainer(ma
x_epochs=5).
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_abl2.py", line 1682, in main
    trainer.fit(model, datamodule=data_module, ckpt_path=model_checkpoint_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.p
y", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/lau
nchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 978, in _run
    self._checkpoint_connector.restore_training_state()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connec
tors/checkpoint_connector.py", line 293, in restore_training_state
    self.restore_loops()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connec
tors/checkpoint_connector.py", line 351, in restore_loops
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: You restored a checkpoint with current_epoch=
7, but you have set Trainer(max_epochs=5).

2024-09-22 18:21:23.156 | INFO     | __main__:main:1689 - Finished progressive training at epoch 7
2024-09-22 18:21:23.157 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:23.157 | INFO     | __main__:main:1696 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
An error occurred during training: You restored a checkpoint with current_epoch=7, but you have set Trainer(ma
x_epochs=5).
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_abl2.py", line 1682, in main
    trainer.fit(model, datamodule=data_module, ckpt_path=model_checkpoint_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.p
y", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/lau
nchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 978, in _run
    self._checkpoint_connector.restore_training_state()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connec
tors/checkpoint_connector.py", line 293, in restore_training_state
    self.restore_loops()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connec
tors/checkpoint_connector.py", line 351, in restore_loops
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: You restored a checkpoint with current_epoch=
7, but you have set Trainer(max_epochs=5).

2024-09-22 18:21:23.166 | INFO     | __main__:main:1689 - Finished progressive training at epoch 7
2024-09-22 18:21:23.166 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:23.166 | INFO     | __main__:main:1696 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
An error occurred during training: You restored a checkpoint with current_epoch=6, but you have set Trainer(ma
x_epochs=5).
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_abl2.py", line 1682, in main
    trainer.fit(model, datamodule=data_module, ckpt_path=model_checkpoint_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.p
y", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/lau
nchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 978, in _run
    self._checkpoint_connector.restore_training_state()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connec
tors/checkpoint_connector.py", line 293, in restore_training_state
    self.restore_loops()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connec
tors/checkpoint_connector.py", line 351, in restore_loops
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: You restored a checkpoint with current_epoch=
6, but you have set Trainer(max_epochs=5).

2024-09-22 18:21:23.252 | INFO     | __main__:main:1689 - Finished progressive training at epoch 6
2024-09-22 18:21:23.253 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:23.253 | INFO     | __main__:main:1696 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
An error occurred during training: You restored a checkpoint with current_epoch=7, but you have set Trainer(ma
x_epochs=5).
Traceback (most recent call last):
  File "/data/yingzi_ma/lean_project/ReProver/main3_abl2.py", line 1682, in main
    trainer.fit(model, datamodule=data_module, ckpt_path=model_checkpoint_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 544, in fit
    call._call_and_handle_interrupt(
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/call.p
y", line 43, in _call_and_handle_interrupt
    return trainer.strategy.launcher.launch(trainer_fn, *args, trainer=trainer, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/strategies/lau
nchers/subprocess_script.py", line 105, in launch
    return function(*args, **kwargs)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 580, in _fit_impl
    self._run(model, ckpt_path=ckpt_path)
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/traine
r.py", line 978, in _run
    self._checkpoint_connector.restore_training_state()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connec
tors/checkpoint_connector.py", line 293, in restore_training_state
    self.restore_loops()
  File "/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/trainer/connec
tors/checkpoint_connector.py", line 351, in restore_loops
    raise MisconfigurationException(
lightning_fabric.utilities.exceptions.MisconfigurationException: You restored a checkpoint with current_epoch=
7, but you have set Trainer(max_epochs=5).

2024-09-22 18:21:23.256 | INFO     | __main__:main:1689 - Finished progressive training at epoch 7
2024-09-22 18:21:23.257 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:23.257 | INFO     | __main__:main:1696 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:25.168 | INFO     | __main__:main:1846 - Finished processing the repository
2024-09-22 18:21:25.168 | INFO     | __main__:main:1848 - current epoch: 5
2024-09-22 18:21:25.168 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:21:25.168 | INFO     | __main__:main:1520 - i: 1
2024-09-22 18:21:25.168 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:21:25.175 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:25.175 | INFO     | __main__:main:1555 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:25.175 | INFO     | __main__:main:1561 - Inside train_test_fisher
2024-09-22 18:21:25.175 | INFO     | __main__:main:1562 - Starting training at epoch 5
[rank: 1] Seed set to 3407
2024-09-22 18:21:25.637 | INFO     | __main__:main:1846 - Finished processing the repository
2024-09-22 18:21:25.637 | INFO     | __main__:main:1848 - current epoch: 5
2024-09-22 18:21:25.637 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:21:25.638 | INFO     | __main__:main:1520 - i: 1
2024-09-22 18:21:25.638 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:21:25.642 | INFO     | __main__:main:1846 - Finished processing the repository
2024-09-22 18:21:25.642 | INFO     | __main__:main:1848 - current epoch: 5
2024-09-22 18:21:25.642 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:25.642 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:21:25.642 | INFO     | __main__:main:1520 - i: 1
2024-09-22 18:21:25.642 | INFO     | __main__:main:1555 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:25.642 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:21:25.642 | INFO     | __main__:main:1561 - Inside train_test_fisher
2024-09-22 18:21:25.643 | INFO     | __main__:main:1562 - Starting training at epoch 5
[rank: 3] Seed set to 3407
2024-09-22 18:21:25.643 | INFO     | __main__:find_latest_checkpoint:707 - Using the latest checkpoint: /data/
yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_
f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:25.643 | INFO     | __main__:main:1555 - Found latest checkpoint: /data/yingzi_ma/lean_projec
t/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c
024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
2024-09-22 18:21:25.643 | INFO     | __main__:main:1561 - Inside train_test_fisher
2024-09-22 18:21:25.643 | INFO     | __main__:main:1562 - Starting training at epoch 5
[rank: 2] Seed set to 3407
2024-09-22 18:21:25.931 | INFO     | __main__:main:1784 - Starting the prover
2024-09-22 18:21:25.932 | INFO     | prover.proof_search:__init__:407 - Inside __init__
2024-09-22 18:21:25.932 | INFO     | prover.proof_search:__init__:412 - ckpt_path is not None
2024-09-22 18:21:25.932 | INFO     | prover.proof_search:__init__:427 - Using RAG
2024-09-22 18:21:25.933 | INFO     | prover.proof_search:find_latest_checkpoint:380 - Using the latest checkpo
int: /data/yingzi_ma/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matri
x-cookbook_f15a149d321ac99ff9b9c024b58e7882f564669f_lambda_0.1_epoch=7-Recall@10_val=70.74.ckpt
^Z
[1]+  Stopped                 bash run_code3_abl2.sh
(base) yingzi_ma@compute-permanent-node-1021:~/lean_project/ReProver$ bash run_code3_abl2.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
Stopping ray
Did not find any active Ray processes.
kill: (6943): Operation not permitted
kill: (7223): Operation not permitted
kill: (1754216): Operation not permitted
kill: (1754655): Operation not permitted
kill: (1754857): Operation not permitted
kill: (1755011): Operation not permitted
kill: (1796073): Operation not permitted
kill: (1796174): Operation not permitted
kill: (1805172): No such process
kill: (1969173): Operation not permitted
kill: (1969210): Operation not permitted
kill: (1969211): Operation not permitted
kill: (1969212): Operation not permitted
kill: (1969219): Operation not permitted
kill: (1970479): Operation not permitted
kill: (1970522): Operation not permitted
kill: (1970523): Operation not permitted
kill: (1970524): Operation not permitted
kill: (1970531): Operation not permitted
kill: (1971213): Operation not permitted
kill: (1971231): Operation not permitted
kill: (1971232): Operation not permitted
kill: (1971233): Operation not permitted
kill: (1971240): Operation not permitted
Sun Sep 22 18:28:21 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:0F:00.0 Off |                    0 |
| N/A   40C    P0             86W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:15:00.0 Off |                    0 |
| N/A   38C    P0             86W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   38C    P0             87W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   41C    P0             91W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running main3_abl2.py
[2024-09-22 18:28:27,470] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (aut
o detect)
2024-09-22 18:28:31.220 | INFO     | __main__:main:1405 - Running retrieval baseline
2024-09-22 18:28:31.221 | INFO     | __main__:main:1408 - Configuring LeanDojo...
2024-09-22 18:28:31.223 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directo
ry: /data/yingzi_ma/lean_project/ReProver
2024-09-22 18:28:31.224 | INFO     | __main__:main:1410 - LeanDojo configured
2024-09-22 18:28:31.224 | INFO     | __main__:main:1415 - Starting the main process
2024-09-22 18:28:31.224 | INFO     | __main__:main:1423 - Loading database from /data/yingzi_ma/lean_project/d
ynamic_database_PT_single_repo_no_ewc_curriculum_abl2.json
2024-09-22 18:29:30.053 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/lecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-22 18:29:30.053 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/lecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-22 18:29:37.262 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/ImperialCollegeLondon/FLT (commit: b208a302cdcbfadce33d8165f0b054bfa17e2147)
2024-09-22 18:29:37.262 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/ImperialCollegeLondon/FLT (commit: b208a302cdcbfadce33d8165f0b054bfa17e2147)
2024-09-22 18:29:39.072 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/teorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-22 18:29:39.072 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/teorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-22 18:29:47.412 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 89bf7b5e3a226525e8580bae21ef543604f99b21)
2024-09-22 18:29:47.413 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 89bf7b5e3a226525e8580bae21ef543604f99b21)
2024-09-22 18:29:58.027 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/dwrensha/compfiles (commit: f99bf6f2928d47dd1a445b414b3a723c2665f091)
2024-09-22 18:29:58.028 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/dwrensha/compfiles (commit: f99bf6f2928d47dd1a445b414b3a723c2665f091)
2024-09-22 18:30:07.918 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/google-deepmind/debate (commit: 7fb39251b705797ee54e08c96177fabd29a5b5a3)
2024-09-22 18:30:07.918 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/google-deepmind/debate (commit: 7fb39251b705797ee54e08c96177fabd29a5b5a3)
2024-09-22 18:30:09.847 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-22 18:30:09.847 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-22 18:30:10.449 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/FormalizedFormalLogic/Foundation (commit: d5fe5d057a90a0703a745cdc318a1b6621490c21)
2024-09-22 18:30:10.450 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/FormalizedFormalLogic/Foundation (commit: d5fe5d057a90a0703a745cdc318a1b6621490c21)
2024-09-22 18:30:10.588 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/digama0/lean4lean (commit: 05b1f4a68c5facea96a5ee51c6a56fef21276e0f)
2024-09-22 18:30:10.589 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/digama0/lean4lean (commit: 05b1f4a68c5facea96a5ee51c6a56fef21276e0f)
2024-09-22 18:30:21.757 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/eric-wieser/lean-matrix-cookbook (commit: f15a149d321ac99ff9b9c024b58e7882f564669f)
2024-09-22 18:30:21.757 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/eric-wieser/lean-matrix-cookbook (commit: f15a149d321ac99ff9b9c024b58e7882f564669f)
2024-09-22 18:30:23.596 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/yuma-mizuno/lean-math-workshop (commit: 5acd4b933d47fd6c1032798a6046c1baf261445d)
2024-09-22 18:30:23.596 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/yuma-mizuno/lean-math-workshop (commit: 5acd4b933d47fd6c1032798a6046c1baf261445d)
2024-09-22 18:30:23.950 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/loganrjmurphy/LeanEuclid (commit: f1912c3090eb82820575758efc31e40b9db86bb8)
2024-09-22 18:30:23.951 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/loganrjmurphy/LeanEuclid (commit: f1912c3090eb82820575758efc31e40b9db86bb8)
2024-09-22 18:30:24.659 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/leanprover-community/con-nf (commit: 00bdc85ba7d486a9e544a0806a1018dd06fa3856)
2024-09-22 18:30:24.659 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/leanprover-community/con-nf (commit: 00bdc85ba7d486a9e544a0806a1018dd06fa3856)
2024-09-22 18:30:24.946 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/siddhartha-gadgil/Saturn (commit: 3811a9dd46cdfd5fa0c0c1896720c28d2ec4a42a)
2024-09-22 18:30:24.947 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/siddhartha-gadgil/Saturn (commit: 3811a9dd46cdfd5fa0c0c1896720c28d2ec4a42a)
2024-09-22 18:30:38.192 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https
://github.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 29baddd685660b5fedd7bd67f9916ae24253d566)
2024-09-22 18:30:38.192 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://githu
b.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 29baddd685660b5fedd7bd67f9916ae24253d566)
2024-09-22 18:30:39.485 | INFO     | __main__:main:1425 - Loaded database from /data/yingzi_ma/lean_project/dy
namic_database_PT_single_repo_no_ewc_curriculum_abl2.json
2024-09-22 18:30:39.487 | INFO     | __main__:main:1432 - Found 9 repositories
2024-09-22 18:30:39.487 | INFO     | __main__:main:1435 - Starting curriculum learning
2024-09-22 18:30:39.881 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc1
2024-09-22 18:30:56.857 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0
2024-09-22 18:31:14.296 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0
2024-09-22 18:31:32.583 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0-rc2
2024-09-22 18:31:50.142 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc2
2024-09-22 18:32:07.165 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:32:07.166 | INFO     | __main__:main:1520 - i: 0
2024-09-22 18:32:07.166 | INFO     | __main__:main:1526 - Main process
2024-09-22 18:32:07.166 | INFO     | __main__:main:1527 - Using lambda = 0.0
2024-09-22 18:32:07.166 | INFO     | __main__:main:1528 - Processing https://github.com/teorth/pfr
2024-09-22 18:32:07.166 | INFO     | __main__:main:1535 - Adding repo to repos_for_merged_dataset
2024-09-22 18:32:07.166 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:32:07.166 | INFO     | __main__:main:1784 - Starting the prover
2024-09-22 18:32:07.166 | INFO     | prover.proof_search:__init__:407 - Inside __init__
2024-09-22 18:32:07.166 | INFO     | prover.proof_search:__init__:412 - ckpt_path is not None
2024-09-22 18:32:07.166 | INFO     | prover.proof_search:__init__:427 - Using RAG
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:5
7: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pi
ckle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code du
ring unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more detail
s). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the funct
ions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via th
is mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We reco
mmend you start setting `weights_only=True` for any use case where you don't have full control of the loaded f
ile. Please open an issue on GitHub for any issues related to this experimental feature.
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-22 18:32:07.919 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:32:07.919 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:32:11.382 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:184: Fo
und keys that are in the model state dict but not in the checkpoint: ['retriever.encoder.shared.weight', 'retr
iever.encoder.encoder.embed_tokens.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.q.weight'
, 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.0.layer
.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.o.weight', 'retriever.enc
oder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'retriever.encoder.encoder.block.0
.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'retrieve
r.encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.0.layer.1.Dens
eReluDense.wo.weight', 'retriever.encoder.encoder.block.0.layer.1.layer_norm.weight', 'retriever.encoder.encod
er.block.1.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.k.weight'
, 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.1.layer
.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.1.layer.0.layer_norm.weight', 'retriever.encoder.
encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense
.wi_1.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encode
r.block.1.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.q.weight', 'ret
riever.encoder.encoder.block.2.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.2.layer.0.Sel
fAttention.v.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.o.weight', 'retriever.encoder.e
ncoder.block.2.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weig
ht', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.
2.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.2.layer.1.layer_norm.weight', 'retriever
.encoder.encoder.block.3.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAtten
tion.k.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder
.block.3.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.3.layer.0.layer_norm.weight', 'retr
iever.encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.3.layer.1.
DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'retriever.
encoder.encoder.block.3.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.q
.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block
.4.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.o.weight', 'retri
ever.encoder.encoder.block.4.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluD
ense.wi_0.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.
encoder.block.4.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.4.layer.1.layer_norm.weigh
t', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.5.lay
er.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.v.weight', 'retriever.e
ncoder.encoder.block.5.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.5.layer.0.layer_norm.
weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.bl
ock.5.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight
', 'retriever.encoder.encoder.block.5.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.6.layer.0.S
elfAttention.q.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.k.weight', 'retriever.encoder
.encoder.block.6.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.o.w
eight', 'retriever.encoder.encoder.block.6.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.6.laye
r.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'retr
iever.encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.6.layer.1.la
yer_norm.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.q.weight', 'retriever.encoder.encod
er.block.7.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.v.weight'
, 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.7.layer
.0.layer_norm.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 'retriever.enco
der.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluD
ense.wo.weight', 'retriever.encoder.encoder.block.7.layer.1.layer_norm.weight', 'retriever.encoder.encoder.blo
ck.8.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.k.weight', 'ret
riever.encoder.encoder.block.8.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.8.layer.0.Sel
fAttention.o.weight', 'retriever.encoder.encoder.block.8.layer.0.layer_norm.weight', 'retriever.encoder.encode
r.block.8.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.
weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.bloc
k.8.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.q.weight', 'retriever
.encoder.encoder.block.9.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAtten
tion.v.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder
.block.9.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', '
retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.9.laye
r.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.9.layer.1.layer_norm.weight', 'retriever.encod
er.encoder.block.10.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention
.k.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.bl
ock.10.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.10.layer.0.layer_norm.weight', 'retri
ever.encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.10.layer.1
.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'retrieve
r.encoder.encoder.block.10.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttenti
on.q.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.
block.11.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.o.weight',
 'retriever.encoder.encoder.block.11.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.1.D
enseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight', 'retrieve
r.encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.11.layer.1.laye
r_norm.weight', 'retriever.encoder.encoder.final_layer_norm.weight']
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188: Fo
und keys that are not in the model state dict but in the checkpoint: ['pytorch-lightning_version', 'global_ste
p', 'epoch', 'state_dict', 'callbacks', 'loops', 'legacy_pytorch-lightning_version', 'hyper_parameters']
2024-09-22 18:32:12.165 | INFO     | prover.proof_search:__init__:452 - Loaded model from /data/yingzi_ma/lean
_project/model_lightning.ckpt
2024-09-22 18:32:12.166 | INFO     | prover.proof_search:__init__:453 - Using retriever: PremiseRetriever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-22 18:32:12.166 | INFO     | prover.proof_search:__init__:456 - Loading indexed corpus from /data/ying
zi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45
e50c6aee013a2687/corpus.jsonl
2024-09-22 18:32:12.166 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687
/corpus.jsonl
2024-09-22 18:32:17.943 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-22 18:32:17.943 | INFO     | prover.proof_search:__init__:458 - Loaded indexed corpus from /data/yingz
i_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e
50c6aee013a2687/corpus.jsonl
2024-09-22 18:32:17.943 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|| 3433/3433 [05:15<00:00, 10.89it/s]
2024-09-22 18:37:33.547 | INFO     | prover.proof_search:__init__:460 - Finished reindexing!
2024-09-22 18:37:33.548 | INFO     | prover.proof_search:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-22 18:37:38,134 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=1842923) [2024-09-22 18:38:16,255] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
(ProverActor pid=1842923) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.
py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
 uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execu
te arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mo
dels for more details). In a future release, the default value for `weights_only` will be flipped to `True`. T
his limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
 to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_sa
fe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full con
trol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=1842923)   return torch.load(io.BytesIO(b))
(pid=1843095) [2024-09-22 18:38:27,885] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
(ProverActor pid=1843095) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.
py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
 uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execu
te arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mo
dels for more details). In a future release, the default value for `weights_only` will be flipped to `True`. T
his limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
 to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_sa
fe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full con
trol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=1843095)   return torch.load(io.BytesIO(b))
(pid=1843447) [2024-09-22 18:38:39,647] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
2024-09-22 18:38:43.159 | INFO     | __main__:prove_sorry_theorems:1012 - Found 37 sorry theorems to prove
Processing theorems from teorth/pfr:   0%|                                        | 0/37 [00:00<?, ?theorem/s]
2024-09-22 18:38:43.160 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multiDist_nonneg
2024-09-22 18:38:43.160 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: rho_plus_of_sum
2024-09-22 18:38:43.160 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: dist_of_min_eq_zero
2024-09-22 18:38:43.160 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: cond_multiDist_chainRule
2024-09-22 18:38:43.160 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: dist_add_dist_eq
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multiDist_indep
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: cor_multiDist_chainRule
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: iter_multiDist_chainRule
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: ent_of_sum_le_ent_of_sum
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: condRho_minus_le
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multiTau_continuous
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multiTau_min_exists
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: rho_of_translate
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: dist_le_of_sum_zero
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: iter_multiDist_chainRule'
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: rho_continuous
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multidist_eq_zero
2024-09-22 18:38:43.161 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: condMultiDist_eq
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: condRho_of_translate
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multidist_ruzsa_IV
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multidist_ruzsa_II
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multidist_ruzsa_III
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: condRho_le
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: condRho_sum_le'
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: condRho_of_sum_le
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: rho_of_sum
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multiDist_chainRule
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: rho_of_subgroup
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: multidist_ruzsa_I
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: condRho_plus_le
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: I_two_le
2024-09-22 18:38:43.162 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: rho_minus_of_sum
2024-09-22 18:38:43.163 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: condRho_of_injective
2024-09-22 18:38:43.163 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: rho_of_sum_le
2024-09-22 18:38:43.163 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: phi_min_exists
2024-09-22 18:38:43.163 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: condRho_sum_le
2024-09-22 18:38:43.163 | INFO     | __main__:prove_sorry_theorems:1025 - Skipping already encountered theorem
: I_one_le
Processing theorems from teorth/pfr: 100%|| 37/37 [00:00<00:00, 12304.89theorem/s]
2024-09-22 18:38:43.163 | INFO     | __main__:save_progress:967 - Saving encountered theorems...
2024-09-22 18:38:43.165 | INFO     | __main__:prove_sorry_theorems:1063 - Finished attempting to prove sorry t
heorems
(ProverActor pid=1843447) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.
py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
 uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execu
te arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mo
dels for more details). In a future release, the default value for `weights_only` will be flipped to `True`. T
his limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
 to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_sa
fe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full con
trol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=1843447)   return torch.load(io.BytesIO(b))
(pid=1843878) [2024-09-22 18:38:50,997] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
(ProverActor pid=1843878) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.
py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
 uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execu
te arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mo
dels for more details). In a future release, the default value for `weights_only` will be flipped to `True`. T
his limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
 to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_sa
fe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full con
trol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=1843878)   return torch.load(io.BytesIO(b))
^Z
[2]+  Stopped                 bash run_code3_abl2.sh
(base) yingzi_ma@compute-permanent-node-1021:~/lean_project/ReProver$ bash run_code3_abl2.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
Stopping ray
Stopped only 257 out of 262 Ray processes within the grace period 16 seconds. Set `-v` to see more details. Re
maining processes [psutil.Process(pid=1811821, name='raylet', status='zombie', started='18:37:36'), psutil.Pro
cess(pid=1811871, name='python', status='zombie', started='18:37:36'), psutil.Process(pid=1811654, name='pytho
n', status='zombie', started='18:37:34'), psutil.Process(pid=1811673, name='python', status='zombie', started=
'18:37:35'), psutil.Process(pid=1811335, name='gcs_server', status='zombie', started='18:37:33')] will be forc
efully terminated.
You can also use `--force` to forcefully terminate processes or set higher `--grace-period` to wait longer tim
e for proper termination.
kill: (6943): Operation not permitted
kill: (7223): Operation not permitted
kill: (1754216): Operation not permitted
kill: (1754655): Operation not permitted
kill: (1754857): Operation not permitted
kill: (1755011): Operation not permitted
kill: (1796073): Operation not permitted
kill: (1796174): Operation not permitted
kill: (1844879): No such process
kill: (1969173): Operation not permitted
kill: (1969210): Operation not permitted
kill: (1969211): Operation not permitted
kill: (1969212): Operation not permitted
kill: (1969219): Operation not permitted
kill: (1970479): Operation not permitted
kill: (1970522): Operation not permitted
kill: (1970523): Operation not permitted
kill: (1970524): Operation not permitted
kill: (1970531): Operation not permitted
kill: (1971213): Operation not permitted
kill: (1971231): Operation not permitted
kill: (1971232): Operation not permitted
kill: (1971233): Operation not permitted
kill: (1971240): Operation not permitted
Sun Sep 22 18:40:35 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:0F:00.0 Off |                    0 |
| N/A   41C    P0             86W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:15:00.0 Off |                    0 |
| N/A   38C    P0             86W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   38C    P0             88W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   42C    P0             91W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Running main3_abl2.py
[2024-09-22 18:40:41,629] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (aut
o detect)
2024-09-22 18:40:45.359 | INFO     | __main__:main:1405 - Running retrieval baseline
2024-09-22 18:40:45.359 | INFO     | __main__:main:1408 - Configuring LeanDojo...
2024-09-22 18:40:45.362 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directo
ry: /data/yingzi_ma/lean_project/ReProver
2024-09-22 18:40:45.362 | INFO     | __main__:main:1410 - LeanDojo configured
2024-09-22 18:40:45.362 | INFO     | __main__:main:1415 - Starting the main process
2024-09-22 18:40:45.362 | INFO     | __main__:main:1423 - Loading database from /data/yingzi_ma/lean_project/d
ynamic_database_PT_single_repo_no_ewc_curriculum_abl2.json
2024-09-22 18:41:01.919 | WARNING  | __main__:main:1428 - Error decoding JSON from /data/yingzi_ma/lean_projec
t/dynamic_database_PT_single_repo_no_ewc_curriculum_abl2.json. Initializing new database.
2024-09-22 18:41:02.097 | INFO     | __main__:main:1432 - Found 9 repositories
2024-09-22 18:41:02.098 | INFO     | __main__:main:1435 - Starting curriculum learning
2024-09-22 18:41:02.428 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc1
2024-09-22 18:41:19.738 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0
2024-09-22 18:41:37.611 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0
2024-09-22 18:41:55.712 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.7.0-rc2
2024-09-22 18:42:13.277 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit h
ash for lean4 v4.8.0-rc2
2024-09-22 18:42:30.562 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:42:30.562 | INFO     | __main__:main:1520 - i: 0
2024-09-22 18:42:30.562 | INFO     | __main__:main:1526 - Main process
2024-09-22 18:42:30.562 | INFO     | __main__:main:1527 - Using lambda = 0.0
2024-09-22 18:42:30.562 | INFO     | __main__:main:1528 - Processing https://github.com/teorth/pfr
2024-09-22 18:42:30.562 | INFO     | __main__:main:1535 - Adding repo to repos_for_merged_dataset
2024-09-22 18:42:30.562 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:42:30.562 | INFO     | __main__:main:1784 - Starting the prover
2024-09-22 18:42:30.563 | INFO     | prover.proof_search:__init__:407 - Inside __init__
2024-09-22 18:42:30.563 | INFO     | prover.proof_search:__init__:412 - ckpt_path is not None
2024-09-22 18:42:30.563 | INFO     | prover.proof_search:__init__:427 - Using RAG
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:5
7: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pi
ckle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code du
ring unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more detail
s). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the funct
ions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via th
is mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We reco
mmend you start setting `weights_only=True` for any use case where you don't have full control of the loaded f
ile. Please open an issue on GitHub for any issues related to this experimental feature.
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-22 18:42:31.041 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:42:31.041 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:42:33.791 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:184: Fo
und keys that are in the model state dict but not in the checkpoint: ['retriever.encoder.shared.weight', 'retr
iever.encoder.encoder.embed_tokens.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.q.weight'
, 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.0.layer
.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.o.weight', 'retriever.enc
oder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'retriever.encoder.encoder.block.0
.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'retrieve
r.encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.0.layer.1.Dens
eReluDense.wo.weight', 'retriever.encoder.encoder.block.0.layer.1.layer_norm.weight', 'retriever.encoder.encod
er.block.1.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.k.weight'
, 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.1.layer
.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.1.layer.0.layer_norm.weight', 'retriever.encoder.
encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense
.wi_1.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encode
r.block.1.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.q.weight', 'ret
riever.encoder.encoder.block.2.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.2.layer.0.Sel
fAttention.v.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.o.weight', 'retriever.encoder.e
ncoder.block.2.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weig
ht', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.
2.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.2.layer.1.layer_norm.weight', 'retriever
.encoder.encoder.block.3.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAtten
tion.k.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder
.block.3.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.3.layer.0.layer_norm.weight', 'retr
iever.encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.3.layer.1.
DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'retriever.
encoder.encoder.block.3.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.q
.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block
.4.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.o.weight', 'retri
ever.encoder.encoder.block.4.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluD
ense.wi_0.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.
encoder.block.4.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.4.layer.1.layer_norm.weigh
t', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.5.lay
er.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.v.weight', 'retriever.e
ncoder.encoder.block.5.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.5.layer.0.layer_norm.
weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.bl
ock.5.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight
', 'retriever.encoder.encoder.block.5.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.6.layer.0.S
elfAttention.q.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.k.weight', 'retriever.encoder
.encoder.block.6.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.o.w
eight', 'retriever.encoder.encoder.block.6.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.6.laye
r.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'retr
iever.encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.6.layer.1.la
yer_norm.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.q.weight', 'retriever.encoder.encod
er.block.7.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.v.weight'
, 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.7.layer
.0.layer_norm.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 'retriever.enco
der.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluD
ense.wo.weight', 'retriever.encoder.encoder.block.7.layer.1.layer_norm.weight', 'retriever.encoder.encoder.blo
ck.8.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.k.weight', 'ret
riever.encoder.encoder.block.8.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.8.layer.0.Sel
fAttention.o.weight', 'retriever.encoder.encoder.block.8.layer.0.layer_norm.weight', 'retriever.encoder.encode
r.block.8.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.
weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.bloc
k.8.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.q.weight', 'retriever
.encoder.encoder.block.9.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAtten
tion.v.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder
.block.9.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', '
retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.9.laye
r.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.9.layer.1.layer_norm.weight', 'retriever.encod
er.encoder.block.10.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention
.k.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.bl
ock.10.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.10.layer.0.layer_norm.weight', 'retri
ever.encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.10.layer.1
.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'retrieve
r.encoder.encoder.block.10.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttenti
on.q.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.
block.11.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.o.weight',
 'retriever.encoder.encoder.block.11.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.1.D
enseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight', 'retrieve
r.encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.11.layer.1.laye
r_norm.weight', 'retriever.encoder.encoder.final_layer_norm.weight']
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188: Fo
und keys that are not in the model state dict but in the checkpoint: ['pytorch-lightning_version', 'global_ste
p', 'epoch', 'state_dict', 'callbacks', 'loops', 'legacy_pytorch-lightning_version', 'hyper_parameters']
2024-09-22 18:42:34.349 | INFO     | prover.proof_search:__init__:452 - Loaded model from /data/yingzi_ma/lean
_project/model_lightning.ckpt
2024-09-22 18:42:34.350 | INFO     | prover.proof_search:__init__:453 - Using retriever: PremiseRetriever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-22 18:42:34.350 | INFO     | prover.proof_search:__init__:456 - Loading indexed corpus from /data/ying
zi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45
e50c6aee013a2687/corpus.jsonl
2024-09-22 18:42:34.350 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e50c6aee013a2687
/corpus.jsonl
2024-09-22 18:42:40.646 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-22 18:42:40.646 | INFO     | prover.proof_search:__init__:458 - Loaded indexed corpus from /data/yingz
i_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e
50c6aee013a2687/corpus.jsonl
2024-09-22 18:42:40.646 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
100%|| 3433/3433 [05:15<00:00, 10.89it/s]
2024-09-22 18:47:56.160 | INFO     | prover.proof_search:__init__:460 - Finished reindexing!
2024-09-22 18:47:56.161 | INFO     | prover.proof_search:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-22 18:47:59,808 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=1882414) [2024-09-22 18:48:37,577] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
(ProverActor pid=1882414) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.
py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
 uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execu
te arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mo
dels for more details). In a future release, the default value for `weights_only` will be flipped to `True`. T
his limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
 to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_sa
fe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full con
trol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=1882414)   return torch.load(io.BytesIO(b))
(pid=1883295) [2024-09-22 18:48:49,804] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
(ProverActor pid=1883295) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.
py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
 uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execu
te arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mo
dels for more details). In a future release, the default value for `weights_only` will be flipped to `True`. T
his limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
 to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_sa
fe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full con
trol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=1883295)   return torch.load(io.BytesIO(b))
(pid=1883690) [2024-09-22 18:49:02,407] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
(ProverActor pid=1883690) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.
py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which
 uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execu
te arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-mo
dels for more details). In a future release, the default value for `weights_only` will be flipped to `True`. T
his limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed
 to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_sa
fe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full con
trol of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
(ProverActor pid=1883690)   return torch.load(io.BytesIO(b))
2024-09-22 18:49:10.543 | INFO     | __main__:load_encountered_theorems:986 - The file encountered_theorems_PT
_single_repo_no_ewc_curriculum_abl2.pkl does not exist. Starting with an empty set.
2024-09-22 18:49:10.544 | INFO     | __main__:save_progress:967 - Saving encountered theorems...
2024-09-22 18:49:10.545 | INFO     | __main__:prove_sorry_theorems:1063 - Finished attempting to prove sorry t
heorems
2024-09-22 18:49:10.546 | INFO     | __main__:main:1823 - Finished searching for proofs of sorry theorems
2024-09-22 18:49:10.547 | INFO     | __main__:main:1826 - Shutting down Ray after proving
2024-09-22 18:49:13.968 | INFO     | __main__:main:1846 - Finished processing the repository
2024-09-22 18:49:13.968 | INFO     | __main__:main:1848 - current epoch: 5
2024-09-22 18:49:13.968 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:49:13.968 | INFO     | __main__:main:1520 - i: 1
2024-09-22 18:49:13.968 | INFO     | __main__:main:1526 - Main process
2024-09-22 18:49:13.969 | INFO     | __main__:main:1527 - Using lambda = 0.0
2024-09-22 18:49:13.969 | INFO     | __main__:main:1528 - Processing https://github.com/lecopivo/SciLean
2024-09-22 18:49:13.969 | INFO     | __main__:main:1535 - Adding repo to repos_for_merged_dataset
2024-09-22 18:49:13.969 | INFO     | dynamic_database:generate_merged_dataset:415 - Merging selected repositor
ies in the database:
2024-09-22 18:49:13.969 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/lec
opivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-22 18:49:13.969 | WARNING  | dynamic_database:safe_remove_dir_path:377 - /data/yingzi_ma/lean_project/
datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e6265574
4 already exists. Removing it now.
2024-09-22 18:49:13.999 | INFO     | dynamic_database:generate_merged_dataset:439 - Exported proofs to /data/y
ingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_SciLean_22d53b2f4e3db2a17
2e71da6eb9c916e62655744
2024-09-22 18:49:14.000 | INFO     | dynamic_database:generate_merged_dataset:442 - Merged and exported corpus
 to /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_SciLean_22d53b
2f4e3db2a172e71da6eb9c916e62655744
2024-09-22 18:49:14.001 | INFO     | dynamic_database:generate_merged_dataset:445 - Exported traced files to /
data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_SciLean_22d53b2f4e3
db2a172e71da6eb9c916e62655744
2024-09-22 18:49:14.001 | INFO     | dynamic_database:generate_merged_dataset:448 - Exported metadata to /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_SciLean_22d53b2f4e3db2a
172e71da6eb9c916e62655744
2024-09-22 18:49:14.002 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:49:14.002 | INFO     | __main__:main:1784 - Starting the prover
2024-09-22 18:49:14.002 | INFO     | prover.proof_search:__init__:407 - Inside __init__
2024-09-22 18:49:14.002 | INFO     | prover.proof_search:__init__:412 - ckpt_path is not None
2024-09-22 18:49:14.002 | INFO     | prover.proof_search:__init__:427 - Using RAG
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:5
7: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pi
ckle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code du
ring unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more detail
s). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the funct
ions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via th
is mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We reco
mmend you start setting `weights_only=True` for any use case where you don't have full control of the loaded f
ile. Please open an issue on GitHub for any issues related to this experimental feature.
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-22 18:49:14.398 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:49:14.399 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:49:16.562 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:184: Fo
und keys that are in the model state dict but not in the checkpoint: ['retriever.encoder.shared.weight', 'retr
iever.encoder.encoder.embed_tokens.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.q.weight'
, 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.0.layer
.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.0.layer.0.SelfAttention.o.weight', 'retriever.enc
oder.encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight', 'retriever.encoder.encoder.block.0
.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.0.layer.1.DenseReluDense.wi_0.weight', 'retrieve
r.encoder.encoder.block.0.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.0.layer.1.Dens
eReluDense.wo.weight', 'retriever.encoder.encoder.block.0.layer.1.layer_norm.weight', 'retriever.encoder.encod
er.block.1.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.k.weight'
, 'retriever.encoder.encoder.block.1.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.1.layer
.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.1.layer.0.layer_norm.weight', 'retriever.encoder.
encoder.block.1.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense
.wi_1.weight', 'retriever.encoder.encoder.block.1.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encode
r.block.1.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.q.weight', 'ret
riever.encoder.encoder.block.2.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.2.layer.0.Sel
fAttention.v.weight', 'retriever.encoder.encoder.block.2.layer.0.SelfAttention.o.weight', 'retriever.encoder.e
ncoder.block.2.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_0.weig
ht', 'retriever.encoder.encoder.block.2.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.
2.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.2.layer.1.layer_norm.weight', 'retriever
.encoder.encoder.block.3.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAtten
tion.k.weight', 'retriever.encoder.encoder.block.3.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder
.block.3.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.3.layer.0.layer_norm.weight', 'retr
iever.encoder.encoder.block.3.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.3.layer.1.
DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.3.layer.1.DenseReluDense.wo.weight', 'retriever.
encoder.encoder.block.3.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.q
.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block
.4.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.4.layer.0.SelfAttention.o.weight', 'retri
ever.encoder.encoder.block.4.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluD
ense.wi_0.weight', 'retriever.encoder.encoder.block.4.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.
encoder.block.4.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.4.layer.1.layer_norm.weigh
t', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.5.lay
er.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.5.layer.0.SelfAttention.v.weight', 'retriever.e
ncoder.encoder.block.5.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.5.layer.0.layer_norm.
weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.bl
ock.5.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.5.layer.1.DenseReluDense.wo.weight
', 'retriever.encoder.encoder.block.5.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.6.layer.0.S
elfAttention.q.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.k.weight', 'retriever.encoder
.encoder.block.6.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.6.layer.0.SelfAttention.o.w
eight', 'retriever.encoder.encoder.block.6.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.6.laye
r.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.6.layer.1.DenseReluDense.wi_1.weight', 'retr
iever.encoder.encoder.block.6.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.6.layer.1.la
yer_norm.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.q.weight', 'retriever.encoder.encod
er.block.7.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.v.weight'
, 'retriever.encoder.encoder.block.7.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.7.layer
.0.layer_norm.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluDense.wi_0.weight', 'retriever.enco
der.encoder.block.7.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.7.layer.1.DenseReluD
ense.wo.weight', 'retriever.encoder.encoder.block.7.layer.1.layer_norm.weight', 'retriever.encoder.encoder.blo
ck.8.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.8.layer.0.SelfAttention.k.weight', 'ret
riever.encoder.encoder.block.8.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.8.layer.0.Sel
fAttention.o.weight', 'retriever.encoder.encoder.block.8.layer.0.layer_norm.weight', 'retriever.encoder.encode
r.block.8.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wi_1.
weight', 'retriever.encoder.encoder.block.8.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.bloc
k.8.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.q.weight', 'retriever
.encoder.encoder.block.9.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAtten
tion.v.weight', 'retriever.encoder.encoder.block.9.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder
.block.9.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_0.weight', '
retriever.encoder.encoder.block.9.layer.1.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.9.laye
r.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.9.layer.1.layer_norm.weight', 'retriever.encod
er.encoder.block.10.layer.0.SelfAttention.q.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention
.k.weight', 'retriever.encoder.encoder.block.10.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.bl
ock.10.layer.0.SelfAttention.o.weight', 'retriever.encoder.encoder.block.10.layer.0.layer_norm.weight', 'retri
ever.encoder.encoder.block.10.layer.1.DenseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.10.layer.1
.DenseReluDense.wi_1.weight', 'retriever.encoder.encoder.block.10.layer.1.DenseReluDense.wo.weight', 'retrieve
r.encoder.encoder.block.10.layer.1.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttenti
on.q.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.k.weight', 'retriever.encoder.encoder.
block.11.layer.0.SelfAttention.v.weight', 'retriever.encoder.encoder.block.11.layer.0.SelfAttention.o.weight',
 'retriever.encoder.encoder.block.11.layer.0.layer_norm.weight', 'retriever.encoder.encoder.block.11.layer.1.D
enseReluDense.wi_0.weight', 'retriever.encoder.encoder.block.11.layer.1.DenseReluDense.wi_1.weight', 'retrieve
r.encoder.encoder.block.11.layer.1.DenseReluDense.wo.weight', 'retriever.encoder.encoder.block.11.layer.1.laye
r_norm.weight', 'retriever.encoder.encoder.final_layer_norm.weight']
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/core/saving.py:188: Fo
und keys that are not in the model state dict but in the checkpoint: ['pytorch-lightning_version', 'global_ste
p', 'epoch', 'state_dict', 'callbacks', 'loops', 'legacy_pytorch-lightning_version', 'hyper_parameters']
2024-09-22 18:49:16.908 | INFO     | prover.proof_search:__init__:452 - Loaded model from /data/yingzi_ma/lean
_project/model_lightning.ckpt
2024-09-22 18:49:16.909 | INFO     | prover.proof_search:__init__:453 - Using retriever: PremiseRetriever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-22 18:49:16.909 | INFO     | prover.proof_search:__init__:456 - Loading indexed corpus from /data/ying
zi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_SciLean_22d53b2f4e3db2a172e7
1da6eb9c916e62655744/corpus.jsonl
2024-09-22 18:49:16.909 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_SciLean_22d53b2f4e3db2a172e71da6eb9c916e6265
5744/corpus.jsonl
2024-09-22 18:49:16.910 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-22 18:49:16.910 | INFO     | prover.proof_search:__init__:458 - Loaded indexed corpus from /data/yingz
i_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_SciLean_22d53b2f4e3db2a172e71
da6eb9c916e62655744/corpus.jsonl
2024-09-22 18:49:16.910 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
0it [00:00, ?it/s]
2024-09-22 18:49:16.911 | INFO     | prover.proof_search:__init__:460 - Finished reindexing!
2024-09-22 18:49:16.911 | INFO     | prover.proof_search:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-22 18:49:20,090 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=1916201) [2024-09-22 18:49:50,641] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
2024-09-22 18:49:52.870 | INFO     | __main__:save_progress:967 - Saving encountered theorems...
2024-09-22 18:49:52.871 | INFO     | __main__:prove_sorry_theorems:1063 - Finished attempting to prove sorry t
heorems
2024-09-22 18:49:52.873 | INFO     | __main__:main:1823 - Finished searching for proofs of sorry theorems
2024-09-22 18:49:52.873 | INFO     | __main__:main:1826 - Shutting down Ray after proving
2024-09-22 18:49:54.889 | INFO     | __main__:main:1846 - Finished processing the repository
2024-09-22 18:49:54.889 | INFO     | __main__:main:1848 - current epoch: 6
2024-09-22 18:49:54.889 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:49:54.889 | INFO     | __main__:main:1520 - i: 2
2024-09-22 18:49:54.890 | INFO     | __main__:main:1526 - Main process
2024-09-22 18:49:54.890 | INFO     | __main__:main:1527 - Using lambda = 0.0
2024-09-22 18:49:54.890 | INFO     | __main__:main:1528 - Processing https://github.com/google-deepmind/debate
2024-09-22 18:49:54.890 | INFO     | __main__:main:1535 - Adding repo to repos_for_merged_dataset
2024-09-22 18:49:54.891 | INFO     | dynamic_database:generate_merged_dataset:415 - Merging selected repositor
ies in the database:
2024-09-22 18:49:54.891 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/goo
gle-deepmind/debate (commit: 7fb39251b705797ee54e08c96177fabd29a5b5a3)
2024-09-22 18:49:54.891 | WARNING  | dynamic_database:safe_remove_dir_path:377 - /data/yingzi_ma/lean_project/
datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b705797ee54e08c96177fabd29a5b5a3
 already exists. Removing it now.
2024-09-22 18:49:54.917 | INFO     | dynamic_database:generate_merged_dataset:439 - Exported proofs to /data/y
ingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b705797ee5
4e08c96177fabd29a5b5a3
2024-09-22 18:49:54.918 | INFO     | dynamic_database:generate_merged_dataset:442 - Merged and exported corpus
 to /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb3925
1b705797ee54e08c96177fabd29a5b5a3
2024-09-22 18:49:54.919 | INFO     | dynamic_database:generate_merged_dataset:445 - Exported traced files to /
data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b705
797ee54e08c96177fabd29a5b5a3
2024-09-22 18:49:54.920 | INFO     | dynamic_database:generate_merged_dataset:448 - Exported metadata to /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b705797e
e54e08c96177fabd29a5b5a3
2024-09-22 18:49:54.920 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:49:54.920 | INFO     | __main__:main:1784 - Starting the prover
2024-09-22 18:49:54.920 | INFO     | prover.proof_search:__init__:407 - Inside __init__
2024-09-22 18:49:54.920 | INFO     | prover.proof_search:__init__:412 - ckpt_path is not None
2024-09-22 18:49:54.920 | INFO     | prover.proof_search:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-22 18:49:55.249 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:49:55.249 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:49:57.338 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-22 18:49:57.671 | INFO     | prover.proof_search:__init__:452 - Loaded model from /data/yingzi_ma/lean
_project/model_lightning.ckpt
2024-09-22 18:49:57.672 | INFO     | prover.proof_search:__init__:453 - Using retriever: PremiseRetriever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-22 18:49:57.672 | INFO     | prover.proof_search:__init__:456 - Loading indexed corpus from /data/ying
zi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b705797ee54e0
8c96177fabd29a5b5a3/corpus.jsonl
2024-09-22 18:49:57.672 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b705797ee54e08c96177fabd29a5b
5a3/corpus.jsonl
2024-09-22 18:49:57.673 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-22 18:49:57.673 | INFO     | prover.proof_search:__init__:458 - Loaded indexed corpus from /data/yingz
i_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_debate_7fb39251b705797ee54e08
c96177fabd29a5b5a3/corpus.jsonl
2024-09-22 18:49:57.673 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
0it [00:00, ?it/s]
2024-09-22 18:49:57.674 | INFO     | prover.proof_search:__init__:460 - Finished reindexing!
2024-09-22 18:49:57.674 | INFO     | prover.proof_search:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-22 18:50:00,907 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=1948190) [2024-09-22 18:50:30,438] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
2024-09-22 18:50:30.865 | INFO     | __main__:save_progress:967 - Saving encountered theorems...
2024-09-22 18:50:30.867 | INFO     | __main__:prove_sorry_theorems:1063 - Finished attempting to prove sorry t
heorems
2024-09-22 18:50:30.868 | INFO     | __main__:main:1823 - Finished searching for proofs of sorry theorems
2024-09-22 18:50:30.868 | INFO     | __main__:main:1826 - Shutting down Ray after proving
2024-09-22 18:50:33.096 | INFO     | __main__:main:1846 - Finished processing the repository
2024-09-22 18:50:33.096 | INFO     | __main__:main:1848 - current epoch: 7
2024-09-22 18:50:33.096 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:50:33.096 | INFO     | __main__:main:1520 - i: 3
2024-09-22 18:50:33.096 | INFO     | __main__:main:1526 - Main process
2024-09-22 18:50:33.096 | INFO     | __main__:main:1527 - Using lambda = 0.0
2024-09-22 18:50:33.096 | INFO     | __main__:main:1528 - Processing https://github.com/eric-wieser/lean-matri
x-cookbook
2024-09-22 18:50:33.096 | INFO     | __main__:main:1535 - Adding repo to repos_for_merged_dataset
2024-09-22 18:50:33.097 | INFO     | dynamic_database:generate_merged_dataset:415 - Merging selected repositor
ies in the database:
2024-09-22 18:50:33.097 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/eri
c-wieser/lean-matrix-cookbook (commit: f15a149d321ac99ff9b9c024b58e7882f564669f)
2024-09-22 18:50:33.097 | WARNING  | dynamic_database:safe_remove_dir_path:377 - /data/yingzi_ma/lean_project/
datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c024b5
8e7882f564669f already exists. Removing it now.
2024-09-22 18:50:33.123 | INFO     | dynamic_database:generate_merged_dataset:439 - Exported proofs to /data/y
ingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a
149d321ac99ff9b9c024b58e7882f564669f
2024-09-22 18:50:33.124 | INFO     | dynamic_database:generate_merged_dataset:442 - Merged and exported corpus
 to /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-co
okbook_f15a149d321ac99ff9b9c024b58e7882f564669f
2024-09-22 18:50:33.125 | INFO     | dynamic_database:generate_merged_dataset:445 - Exported traced files to /
data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookboo
k_f15a149d321ac99ff9b9c024b58e7882f564669f
2024-09-22 18:50:33.125 | INFO     | dynamic_database:generate_merged_dataset:448 - Exported metadata to /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f1
5a149d321ac99ff9b9c024b58e7882f564669f
2024-09-22 18:50:33.125 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:50:33.125 | INFO     | __main__:main:1784 - Starting the prover
2024-09-22 18:50:33.125 | INFO     | prover.proof_search:__init__:407 - Inside __init__
2024-09-22 18:50:33.126 | INFO     | prover.proof_search:__init__:412 - ckpt_path is not None
2024-09-22 18:50:33.126 | INFO     | prover.proof_search:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-22 18:50:33.399 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:50:33.399 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:50:35.467 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-22 18:50:35.798 | INFO     | prover.proof_search:__init__:452 - Loaded model from /data/yingzi_ma/lean
_project/model_lightning.ckpt
2024-09-22 18:50:35.799 | INFO     | prover.proof_search:__init__:453 - Using retriever: PremiseRetriever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-22 18:50:35.799 | INFO     | prover.proof_search:__init__:456 - Loading indexed corpus from /data/ying
zi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149
d321ac99ff9b9c024b58e7882f564669f/corpus.jsonl
2024-09-22 18:50:35.799 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d321ac99ff9b9c02
4b58e7882f564669f/corpus.jsonl
2024-09-22 18:50:35.800 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-22 18:50:35.800 | INFO     | prover.proof_search:__init__:458 - Loaded indexed corpus from /data/yingz
i_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_lean-matrix-cookbook_f15a149d
321ac99ff9b9c024b58e7882f564669f/corpus.jsonl
2024-09-22 18:50:35.800 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
0it [00:00, ?it/s]
2024-09-22 18:50:35.801 | INFO     | prover.proof_search:__init__:460 - Finished reindexing!
2024-09-22 18:50:35.801 | INFO     | prover.proof_search:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-22 18:50:39,120 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265
(pid=1981153) [2024-09-22 18:51:08,917] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerato
r to cuda (auto detect)
2024-09-22 18:51:09.035 | INFO     | __main__:save_progress:967 - Saving encountered theorems...
2024-09-22 18:51:09.037 | INFO     | __main__:prove_sorry_theorems:1063 - Finished attempting to prove sorry t
heorems
2024-09-22 18:51:09.039 | INFO     | __main__:main:1823 - Finished searching for proofs of sorry theorems
2024-09-22 18:51:09.039 | INFO     | __main__:main:1826 - Shutting down Ray after proving
2024-09-22 18:51:11.221 | INFO     | __main__:main:1846 - Finished processing the repository
2024-09-22 18:51:11.222 | INFO     | __main__:main:1848 - current epoch: 8
2024-09-22 18:51:11.222 | INFO     | __main__:main:1519 - length of lean_git_repos: 9
2024-09-22 18:51:11.222 | INFO     | __main__:main:1520 - i: 4
2024-09-22 18:51:11.222 | INFO     | __main__:main:1526 - Main process
2024-09-22 18:51:11.222 | INFO     | __main__:main:1527 - Using lambda = 0.0
2024-09-22 18:51:11.222 | INFO     | __main__:main:1528 - Processing https://github.com/leanprover-community/c
on-nf
2024-09-22 18:51:11.222 | INFO     | __main__:main:1535 - Adding repo to repos_for_merged_dataset
2024-09-22 18:51:11.223 | INFO     | dynamic_database:generate_merged_dataset:415 - Merging selected repositor
ies in the database:
2024-09-22 18:51:11.223 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/lea
nprover-community/con-nf (commit: 00bdc85ba7d486a9e544a0806a1018dd06fa3856)
2024-09-22 18:51:11.223 | WARNING  | dynamic_database:safe_remove_dir_path:377 - /data/yingzi_ma/lean_project/
datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_con-nf_00bdc85ba7d486a9e544a0806a1018dd06fa3856
 already exists. Removing it now.
2024-09-22 18:51:11.257 | INFO     | dynamic_database:generate_merged_dataset:439 - Exported proofs to /data/y
ingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_con-nf_00bdc85ba7d486a9e5
44a0806a1018dd06fa3856
2024-09-22 18:51:11.258 | INFO     | dynamic_database:generate_merged_dataset:442 - Merged and exported corpus
 to /data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_con-nf_00bdc85
ba7d486a9e544a0806a1018dd06fa3856
2024-09-22 18:51:11.259 | INFO     | dynamic_database:generate_merged_dataset:445 - Exported traced files to /
data/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_con-nf_00bdc85ba7d4
86a9e544a0806a1018dd06fa3856
2024-09-22 18:51:11.259 | INFO     | dynamic_database:generate_merged_dataset:448 - Exported metadata to /data
/yingzi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_con-nf_00bdc85ba7d486a9
e544a0806a1018dd06fa3856
2024-09-22 18:51:11.259 | INFO     | __main__:main:1548 - All GPUs
2024-09-22 18:51:11.260 | INFO     | __main__:main:1784 - Starting the prover
2024-09-22 18:51:11.260 | INFO     | prover.proof_search:__init__:407 - Inside __init__
2024-09-22 18:51:11.260 | INFO     | prover.proof_search:__init__:412 - ckpt_path is not None
2024-09-22 18:51:11.260 | INFO     | prover.proof_search:__init__:427 - Using RAG
Lightning automatically upgraded your loaded checkpoint from v0.0.0 to v2.2.4. To apply the upgrade to your fi
les permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../model_lightning.ckpt`
2024-09-22 18:51:11.435 | INFO     | generator.model:__init__:124 - Retriever checkpoint path: /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:51:11.435 | INFO     | generator.model:__init__:138 - Loading the retriever from /data/yingzi_ma
/lean_project/checkpoints_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_pfr_fa398a5b853c7e94e3294c45e5
0c6aee013a2687_lambda_0.1_epoch=4-Recall@10_val=63.49.ckpt
2024-09-22 18:51:13.575 | INFO     | generator.model:__init__:151 - RetrievalAugmentedGenerator initialized
2024-09-22 18:51:13.944 | INFO     | prover.proof_search:__init__:452 - Loaded model from /data/yingzi_ma/lean
_project/model_lightning.ckpt
2024-09-22 18:51:13.945 | INFO     | prover.proof_search:__init__:453 - Using retriever: PremiseRetriever(
  (encoder): T5EncoderModel(
    (shared): Embedding(384, 1472)
    (encoder): T5Stack(
      (embed_tokens): Embedding(384, 1472)
      (block): ModuleList(
        (0): T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
                (relative_attention_bias): Embedding(32, 6)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
        (1-11): 11 x T5Block(
          (layer): ModuleList(
            (0): T5LayerSelfAttention(
              (SelfAttention): T5Attention(
                (q): Linear(in_features=1472, out_features=384, bias=False)
                (k): Linear(in_features=1472, out_features=384, bias=False)
                (v): Linear(in_features=1472, out_features=384, bias=False)
                (o): Linear(in_features=384, out_features=1472, bias=False)
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (1): T5LayerFF(
              (DenseReluDense): T5DenseGatedActDense(
                (wi_0): Linear(in_features=1472, out_features=3584, bias=False)
                (wi_1): Linear(in_features=1472, out_features=3584, bias=False)
                (wo): Linear(in_features=3584, out_features=1472, bias=False)
                (dropout): Dropout(p=0.1, inplace=False)
                (act): NewGELUActivation()
              )
              (layer_norm): T5LayerNorm()
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
        )
      )
      (final_layer_norm): T5LayerNorm()
      (dropout): Dropout(p=0.1, inplace=False)
    )
  )
)
2024-09-22 18:51:13.945 | INFO     | prover.proof_search:__init__:456 - Loading indexed corpus from /data/ying
zi_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_con-nf_00bdc85ba7d486a9e544a
0806a1018dd06fa3856/corpus.jsonl
2024-09-22 18:51:13.945 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_proje
ct/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_con-nf_00bdc85ba7d486a9e544a0806a1018dd06fa3
856/corpus.jsonl
2024-09-22 18:51:13.946 | INFO     | retrieval.model:load_corpus:159 - Embeddings staled load corpus jsonl: Tr
ue
2024-09-22 18:51:13.946 | INFO     | prover.proof_search:__init__:458 - Loaded indexed corpus from /data/yingz
i_ma/lean_project/datasets_PT_single_repo_no_ewc_curriculum_abl2/merged_with_new_con-nf_00bdc85ba7d486a9e544a0
806a1018dd06fa3856/corpus.jsonl
2024-09-22 18:51:13.946 | INFO     | retrieval.model:reindex_corpus:286 - Re-indexing the retrieval corpus
0it [00:00, ?it/s]
2024-09-22 18:51:13.946 | INFO     | prover.proof_search:__init__:460 - Finished reindexing!
2024-09-22 18:51:13.947 | INFO     | prover.proof_search:__init__:471 - Launching 4 workers with 4 GPUs.
2024-09-22 18:51:17,370 INFO worker.py:1774 -- Started a local Ray instance. View the dashboard at 127.0.0.1:8
265

