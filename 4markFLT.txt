 actors. Consider creating fewer actors or adding more nodes to this Ray cluster.
(autoscaler +7h59m50s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h22s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes
 to this Ray cluster.
(autoscaler +8h2m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h2m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h2m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h3m25s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h5m1s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more node
s to this Ray cluster.
(autoscaler +8h5m1s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more node
s to this Ray cluster.
(autoscaler +8h5m1s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more node
s to this Ray cluster.
(autoscaler +8h5m1s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more node
s to this Ray cluster.
(autoscaler +8h5m33s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h6m37s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h7m8s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more node
s to this Ray cluster.
(autoscaler +8h8m15s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h8m48s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h9m18s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h9m18s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h9m47s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h11m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h11m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h11m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h12m17s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h12m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h13m48s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h14m50s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h15m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h16m17s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h16m17s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h16m17s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h17m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h18m18s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h18m18s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h19m16s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h19m47s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h20m52s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h23m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h23m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h23m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h23m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h23m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h23m56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h25m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h25m53s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h25m53s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h27m24s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h28m25s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h29m25s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h30m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h31m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h31m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h32m25s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h33m22s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h33m22s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h33m22s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h33m22s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h33m22s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h33m22s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h35m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h35m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h35m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h36m18s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h36m18s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h37m52s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h37m52s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h38m24s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h41m27s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h41m56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h41m56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h41m56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h42m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h42m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h43m29s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h43m29s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h45m0s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h46m0s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h46m30s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h47m29s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h47m29s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h48m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h48m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h48m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h48m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h48m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h51m3s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h51m3s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h52m35s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h52m35s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h52m35s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h53m39s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h54m8s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h54m8s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h54m8s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +8h54m40s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h55m16s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h55m50s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h56m53s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h57m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h57m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h58m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +8h59m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes
 to this Ray cluster.
(autoscaler +9h56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes
 to this Ray cluster.
(autoscaler +9h56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nodes
 to this Ray cluster.
(autoscaler +9h1m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h2m33s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h2m33s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h3m42s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h4m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h4m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h5m14s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h6m14s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h6m14s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h7m16s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h7m16s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h7m48s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h8m20s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h9m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h10m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h10m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h10m59s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h12m3s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h12m3s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h12m36s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h13m10s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h13m39s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h14m37s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h15m9s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h16m44s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h16m44s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h16m44s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h17m43s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h18m13s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h19m13s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h19m13s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h20m46s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h22m17s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h22m17s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h22m48s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h22m48s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h23m19s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h27m2s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m7s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m7s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m7s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m7s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m7s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m7s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m7s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m7s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m7s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +9h29m41s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h30m40s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h31m10s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h31m10s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h33m46s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h33m46s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h33m46s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h33m46s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h34m14s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h34m43s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h36m14s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h36m45s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h36m45s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h38m46s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h39m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h39m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h39m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h39m49s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h41m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h42m56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h42m56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h42m56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h43m28s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h43m29s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h44m31s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h45m37s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h45m37s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h47m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h47m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h47m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h47m40s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h49m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h49m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h49m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h49m41s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h50m47s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h51m20s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h52m21s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h52m50s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h52m50s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h54m21s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h54m21s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h54m52s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h55m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h55m53s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h56m54s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h57m21s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h57m21s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h59m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h59m37s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +9h59m37s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h2m32s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h4m5s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +10h4m5s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +10h4m5s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +10h4m5s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +10h4m5s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +10h4m5s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +10h4m5s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +10h5m37s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h5m37s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h6m40s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h6m40s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h7m39s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h7m39s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h8m9s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +10h9m9s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more nod
es to this Ray cluster.
(autoscaler +10h10m14s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h11m15s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h13m16s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h14m16s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h16m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h16m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h16m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h16m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h16m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h16m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h16m55s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h17m57s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h19m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h19m26s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h19m57s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h19m57s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h21m35s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h21m35s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h21m35s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h21m35s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h21m35s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h22m6s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h23m38s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h24m10s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h24m10s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h25m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h25m11s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h26m8s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more no
des to this Ray cluster.
(autoscaler +10h27m40s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h27m40s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h30m13s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h30m13s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h30m13s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h30m42s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h31m41s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h31m41s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h31m41s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h31m41s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h33m13s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h33m13s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h33m44s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h34m51s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h35m56s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h36m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
(autoscaler +10h36m23s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
2024-09-12 14:11:24.084 | INFO     | __main__:prove_sorry_theorems:829 - Found 0 sorry theorems to prove
Processing theorems from yuma-mizuno/lean-math-workshop: 0theorem [00:00, ?theorem/s]
2024-09-12 14:11:24.084 | INFO     | __main__:prove_sorry_theorems:829 - Found 5 sorry theorems to prove
(autoscaler +10h36m45s) Warning: The following resource request cannot be scheduled right now: {'CPU': 1.0, 'GPU': 1.0}. This is likely due to all cluster resources being claimed by actors. Consider creating fewer actors or adding more n
odes to this Ray cluster.
Processing theorems from dwrensha/compfiles:   0%|                | 0/5 [00:00<?, ?theorem/s]2024-09-12 14:11:24.086 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: Imo2008P5.even_subsets_card
2024-09-12 14:11:24.086 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: Bulgaria1998P6.lemma_1'
2024-09-12 14:11:24.086 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: Imo2009P6.imo2009_p6_aux1
2024-09-12 14:11:24.086 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: Imo2001P1.lemma1
2024-09-12 14:11:24.087 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: Imo2008P5.claim
Processing theorems from dwrensha/compfiles: 100%|| 5/5 [00:00<00:00, 4430.91theorem/s]
2024-09-12 14:11:24.087 | INFO     | __main__:prove_sorry_theorems:829 - Found 27 sorry theorems to prove
Processing theorems from AlexKontorovich/PrimeNumberTheoremAnd:   0%| | 0/27 [00:00<?, ?theor2024-09-12 14:11:24.087 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: SmoothedChebyshevClose
2024-09-12 14:11:24.087 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: primorial_bounds
2024-09-12 14:11:24.087 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: primorial_bounds_finprod
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: chebyshev_asymptotic
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: pi_asymp
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: MellinInversion_aux4
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: lambda_pnt
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: prime_between
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: pi_alt
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: integrable_x_mul_Smooth1
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: continuousAt_Smooth1
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: MediumPNT
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: chebyshev_asymptotic_finsum
2024-09-12 14:11:24.088 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: vertical_integrable_Smooth1
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: ZetaDerivUpperBnd''
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: MellinInversion_aux2
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: crude_upper_bound
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: pn_pn_plus_one
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: SmoothedChebyshevDirichlet
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: auto_cheby
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: pn_asymptotic
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: limiting_fourier_variant
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: mu_pnt_alt
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: DerivUpperBnd_aux7
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: mu_pnt
2024-09-12 14:11:24.089 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: MellinInversion_aux1
2024-09-12 14:11:24.090 | INFO     | __main__:prove_sorry_theorems:842 - Skipping already encountered theorem: MellinInversion_aux3
Processing theorems from AlexKontorovich/PrimeNumberTheoremAnd: 100%|| 27/27 [00:00<00:00, 1(pid=2825385) [2024-09-12 14:11:23,658] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)

2024-09-12 14:11:43.166 | INFO     | __main__:save_progress:784 - Saving encountered theorems...
(ProverActor pid=2825385) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default
 pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a futur
e release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explici
tly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issu
es related to this experimental feature.
(ProverActor pid=2825385)   return torch.load(io.BytesIO(b))
(ProverActor pid=2474476) 2024-09-12 05:27:01.200 | INFO     | prover.proof_search:search:128 - SearchResult(theorem=Theorem(repo=LeanGitRepo(url='https://github.com/AlexKontorovich/PrimeNumberTheoremAnd', commit='29baddd685660b5fedd7bd6
7f9916ae24253d566'), file_path=PosixPath('PrimeNumberTheoremAnd/MellinCalculus.lean'), full_name='MellinInversion_aux3'), status=<Status.OPEN: 'Open'>, proof=None, actor_time=306.7291531637311, environment_time=18.762799729127437, total_
time=600.9522639471106, num_total_nodes=484, num_searched_nodes=9)
2024-09-12 14:12:20.747 | INFO     | __main__:prove_sorry_theorems:880 - Finished attempting to prove sorry theorems
(ProverActor pid=2825510) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default
 pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a futur
e release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explici
tly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issu
es related to this experimental feature.
(ProverActor pid=2825510)   return torch.load(io.BytesIO(b))
(pid=2829496) [2024-09-12 14:17:27,400] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect) [repeated 2x across cluster]
(ProverActor pid=2829496) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default
 pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a futur
e release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explici
tly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issu
es related to this experimental feature.
(ProverActor pid=2829496)   return torch.load(io.BytesIO(b))
(pid=2859008) [2024-09-12 15:09:39,292] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
(ProverActor pid=2859008) /data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default
 pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a futur
e release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explici
tly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issu
es related to this experimental feature.
(ProverActor pid=2859008)   return torch.load(io.BytesIO(b))
^Z^C^Z
[3]+  Stopped                 bash run_code4.sh
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ bash run_code4.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
Stopping ray
Could not terminate `/usr/bin/python3 /usr/local/bin/user_traffic_monitor.py` due to (pid=1715738, name='python3')
Stopped only 257 out of 262 Ray processes within the grace period 16 seconds. Set `-v` to see more details. Remaining processes [psutil.Process(pid=2441632, name='raylet', status='zombie', started='03:51:45'), psutil.Process(pid=2441375,
 name='python', status='zombie', started='03:51:42'), psutil.Process(pid=2441386, name='python', status='zombie', started='03:51:43'), psutil.Process(pid=2441711, name='python', status='zombie', started='03:51:46'), psutil.Process(pid=24
41118, name='gcs_server', status='zombie', started='03:51:41')] will be forcefully terminated.
You can also use `--force` to forcefully terminate processes or set higher `--grace-period` to wait longer time for proper termination.
Running main4.py
^Z
[4]+  Stopped                 bash run_code4.sh
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ nvidia-smi
Thu Sep 12 15:23:59 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:8C:00.0 Off |                    0 |
| N/A   36C    P0             85W /  400W |   23649MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:91:00.0 Off |                    0 |
| N/A   36C    P0             87W /  400W |    4605MiB /  81920MiB |    100%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   36C    P0             89W /  400W |    4605MiB /  81920MiB |    100%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   39C    P0             86W /  400W |    4461MiB /  81920MiB |    100%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|    0   N/A  N/A   2431132      C   python                                      11558MiB |
|    0   N/A  N/A   2433818      C   ...miniconda3/envs/ReProver/bin/python       4024MiB |
|    0   N/A  N/A   2433819      C   ...miniconda3/envs/ReProver/bin/python       4024MiB |
|    0   N/A  N/A   2433820      C   ...miniconda3/envs/ReProver/bin/python       4024MiB |
|    1   N/A  N/A   2433818      C   ...miniconda3/envs/ReProver/bin/python       4598MiB |
|    2   N/A  N/A   2433819      C   ...miniconda3/envs/ReProver/bin/python       4598MiB |
|    3   N/A  N/A   2433820      C   ...miniconda3/envs/ReProver/bin/python       4454MiB |
+-----------------------------------------------------------------------------------------+
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ python ppl_gpus.py
GPU UUID                                      PID  User       Process Name      GPU Memory Usage (MB)    GPU Index  GPU Name
----------------------------------------  -------  ---------  --------------  -----------------------  -----------  ---------------------
GPU-dd1cf7cd-ac98-c337-9e7c-19bdf721c9e5  2431132  yingzi_ma  pt_main_thread                    11558            0  NVIDIA A100-SXM4-80GB
GPU-dd1cf7cd-ac98-c337-9e7c-19bdf721c9e5  2433818  yingzi_ma  pt_main_thread                     4024            0  NVIDIA A100-SXM4-80GB
GPU-dd1cf7cd-ac98-c337-9e7c-19bdf721c9e5  2433819  yingzi_ma  pt_main_thread                     4024            0  NVIDIA A100-SXM4-80GB
GPU-dd1cf7cd-ac98-c337-9e7c-19bdf721c9e5  2433820  yingzi_ma  pt_main_thread                     4024            0  NVIDIA A100-SXM4-80GB
GPU-dc6246ee-81ae-c285-1de0-81f9496da679  2433818  yingzi_ma  pt_main_thread                     4598            1  NVIDIA A100-SXM4-80GB
GPU-3f3bde60-06bd-7f7d-a815-0335843bb4d5  2433819  yingzi_ma  pt_main_thread                     4598            2  NVIDIA A100-SXM4-80GB
GPU-d698b8a4-da51-2b4a-2dc7-438864a88433  2433820  yingzi_ma  pt_main_thread                     4454            3  NVIDIA A100-SXM4-80GB
Killed process 2431132
Killed process 2433818
Killed process 2433819
Killed process 2433820
Killed process 2433818
Killed process 2433819
Killed process 2433820
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ nvidia-smi
Thu Sep 12 15:24:04 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:8C:00.0 Off |                    0 |
| N/A   36C    P0             88W /  400W |   19622MiB /  81920MiB |     55%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:91:00.0 Off |                    0 |
| N/A   36C    P0             84W /  400W |    4605MiB /  81920MiB |    100%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   36C    P0             86W /  400W |     580MiB /  81920MiB |     49%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   39C    P0             85W /  400W |     148MiB /  81920MiB |     67%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ nvidia-smi
Thu Sep 12 15:24:06 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:8C:00.0 Off |                    0 |
| N/A   36C    P0             85W /  400W |   11562MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:91:00.0 Off |                    0 |
| N/A   36C    P0             83W /  400W |     289MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   36C    P0             84W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   38C    P0             81W /  400W |     145MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ python ppl_gpus.py
GPU UUID                                      PID  User       Process Name      GPU Memory Usage (MB)    GPU Index  GPU Name
----------------------------------------  -------  ---------  --------------  -----------------------  -----------  ---------------------
GPU-dd1cf7cd-ac98-c337-9e7c-19bdf721c9e5  2431132  yingzi_ma  pt_main_thread                    11558            0  NVIDIA A100-SXM4-80GB
Killed process 2431132
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ nvidia-smi
Thu Sep 12 15:24:11 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:8C:00.0 Off |                    0 |
| N/A   36C    P0             85W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:91:00.0 Off |                    0 |
| N/A   36C    P0             83W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   36C    P0             84W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   38C    P0             81W /  400W |       1MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ bash run_code4.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
Stopping ray
Could not terminate `/usr/bin/python3 /usr/local/bin/user_traffic_monitor.py` due to (pid=1715738, name='python3')
Did not find any active Ray processes.
Running main4.py
[2024-09-12 15:24:25,734] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-12 15:24:29.707 | INFO     | __main__:main:1205 - Running progressive training
2024-09-12 15:24:29.707 | INFO     | __main__:main:1211 - Configuring LeanDojo...
2024-09-12 15:24:29.710 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-12 15:24:29.710 | INFO     | __main__:main:1213 - LeanDojo configured
2024-09-12 15:24:29.710 | INFO     | __main__:main:1218 - Starting the main process
2024-09-12 15:24:29.711 | INFO     | __main__:main:1221 - Initializing new database at /data/yingzi_ma/lean_project/dynamic_database_PT_merge_all_no_ewc_curriculum.json
2024-09-12 15:24:29.712 | INFO     | __main__:main:1235 - Found 15 repositories
2024-09-12 15:24:29.713 | INFO     | __main__:main:1238 - Starting curriculum learning
2024-09-12 15:24:30.170 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0
2024-09-12 15:24:47.321 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
2024-09-12 15:25:04.270 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
^Z
[5]+  Stopped                 bash run_code4.sh
(base) yingzi_ma@compute-permanent-node-834:~/lean_pr
(base) yingzi_ma@compute-permanent-node-
(base) yingzi_ma@compute-permanent-node-
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ cp proof_log_PT_single_repo_no_ewc_curriculum.log proof_log_PT_merge_all_no_ewc_curriculum.lognvidia-^C
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ nvidia-smi
Thu Sep 12 19:08:43 2024
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:8C:00.0 Off |                    0 |
| N/A   36C    P0             85W /  400W |       4MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:91:00.0 Off |                    0 |
| N/A   36C    P0             83W /  400W |       4MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:D6:00.0 Off |                    0 |
| N/A   36C    P0             84W /  400W |       4MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:DA:00.0 Off |                    0 |
| N/A   38C    P0             81W /  400W |       4MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
(base) yingzi_ma@compute-permanent-node-834:~/lean_project/ReProver$ bash run_code4.sh
Script executed from: /data/yingzi_ma/lean_project/ReProver
Removing old cache files
Stopping ray
Could not terminate `/usr/bin/python3 /usr/local/bin/user_traffic_monitor.py` due to (pid=1715738, name='python3')
Did not find any active Ray processes.
Running main4.py
[2024-09-12 19:08:58,306] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-12 19:09:03.641 | INFO     | __main__:main:1205 - Running progressive training
2024-09-12 19:09:03.641 | INFO     | __main__:main:1211 - Configuring LeanDojo...
2024-09-12 19:09:03.644 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-12 19:09:03.644 | INFO     | __main__:main:1213 - LeanDojo configured
2024-09-12 19:09:03.644 | INFO     | __main__:main:1218 - Starting the main process
2024-09-12 19:09:03.644 | INFO     | __main__:main:1226 - Loading database from /data/yingzi_ma/lean_project/dynamic_database_PT_merge_all_no_ewc_curriculum.json
2024-09-12 19:09:53.307 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/lecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-12 19:09:53.307 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/lecopivo/SciLean (commit: 22d53b2f4e3db2a172e71da6eb9c916e62655744)
2024-09-12 19:09:59.274 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/ImperialCollegeLondon/FLT (commit: b208a302cdcbfadce33d8165f0b054bfa17e2147)
2024-09-12 19:09:59.275 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/ImperialCollegeLondon/FLT (commit: b208a302cdcbfadce33d8165f0b054bfa17e2147)
2024-09-12 19:10:06.132 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/teorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-12 19:10:06.132 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/teorth/pfr (commit: fa398a5b853c7e94e3294c45e50c6aee013a2687)
2024-09-12 19:10:13.801 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 29baddd685660b5fedd7bd67f9916ae24253d566)
2024-09-12 19:10:13.801 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 29baddd685660b5fedd7bd67f9916ae24253d566)
2024-09-12 19:10:23.706 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/dwrensha/compfiles (commit: f99bf6f2928d47dd1a445b414b3a723c2665f091)
2024-09-12 19:10:23.706 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/dwrensha/compfiles (commit: f99bf6f2928d47dd1a445b414b3a723c2665f091)
2024-09-12 19:10:32.829 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/google-deepmind/debate (commit: 7fb39251b705797ee54e08c96177fabd29a5b5a3)
2024-09-12 19:10:32.829 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/google-deepmind/debate (commit: 7fb39251b705797ee54e08c96177fabd29a5b5a3)
2024-09-12 19:10:34.741 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-12 19:10:34.741 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-12 19:10:34.879 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/digama0/lean4lean (commit: 05b1f4a68c5facea96a5ee51c6a56fef21276e0f)
2024-09-12 19:10:34.879 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/digama0/lean4lean (commit: 05b1f4a68c5facea96a5ee51c6a56fef21276e0f)
2024-09-12 19:10:36.425 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/eric-wieser/lean-matrix-cookbook (commit: f15a149d321ac99ff9b9c024b58e7882f564669f)
2024-09-12 19:10:36.425 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/eric-wieser/lean-matrix-cookbook (commit: f15a149d321ac99ff9b9c024b58e7882f564669f)
2024-09-12 19:10:47.104 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/yuma-mizuno/lean-math-workshop (commit: 5acd4b933d47fd6c1032798a6046c1baf261445d)
2024-09-12 19:10:47.104 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/yuma-mizuno/lean-math-workshop (commit: 5acd4b933d47fd6c1032798a6046c1baf261445d)
2024-09-12 19:10:47.456 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/loganrjmurphy/LeanEuclid (commit: f1912c3090eb82820575758efc31e40b9db86bb8)
2024-09-12 19:10:47.456 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/loganrjmurphy/LeanEuclid (commit: f1912c3090eb82820575758efc31e40b9db86bb8)
2024-09-12 19:10:48.054 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/FormalizedFormalLogic/Foundation (commit: d5fe5d057a90a0703a745cdc318a1b6621490c21)
2024-09-12 19:10:48.054 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/FormalizedFormalLogic/Foundation (commit: d5fe5d057a90a0703a745cdc318a1b6621490c21)
2024-09-12 19:10:48.193 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/leanprover-community/lean-auto (commit: 0f5f39a0336e36ae4ba8ab45b27865ebd9f8f025)
2024-09-12 19:10:48.193 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/leanprover-community/lean-auto (commit: 0f5f39a0336e36ae4ba8ab45b27865ebd9f8f025)
2024-09-12 19:10:48.279 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/nomeata/loogle (commit: 387ab85308ce817bb95cc99730025eb44cb8a9ab)
2024-09-12 19:10:48.279 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/nomeata/loogle (commit: 387ab85308ce817bb95cc99730025eb44cb8a9ab)
2024-09-12 19:10:48.985 | INFO     | dynamic_database:add_repository:600 - Attempting to add repository: https://github.com/leanprover-community/con-nf (commit: 00bdc85ba7d486a9e544a0806a1018dd06fa3856)
2024-09-12 19:10:48.985 | INFO     | dynamic_database:add_repository:603 - Added new repository: https://github.com/leanprover-community/con-nf (commit: 00bdc85ba7d486a9e544a0806a1018dd06fa3856)
2024-09-12 19:10:50.094 | INFO     | __main__:main:1228 - Loaded database from /data/yingzi_ma/lean_project/dynamic_database_PT_merge_all_no_ewc_curriculum.json
2024-09-12 19:10:50.095 | INFO     | __main__:main:1235 - Found 15 repositories
2024-09-12 19:10:50.096 | INFO     | __main__:main:1238 - Starting curriculum learning
2024-09-12 19:10:50.660 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
2024-09-12 19:11:07.147 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
2024-09-12 19:11:23.616 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0
2024-09-12 19:11:40.173 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0
2024-09-12 19:11:57.686 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0-rc2
2024-09-12 19:12:15.890 | INFO     | __main__:main:1296 - length of lean_git_repos: 11
2024-09-12 19:12:15.891 | INFO     | __main__:main:1297 - i: 0
2024-09-12 19:12:15.891 | INFO     | __main__:main:1303 - Main process
2024-09-12 19:12:15.891 | INFO     | __main__:main:1304 - Using lambda = 0.1
2024-09-12 19:12:15.891 | INFO     | __main__:main:1305 - Processing https://github.com/ImperialCollegeLondon/FLT
2024-09-12 19:12:15.891 | INFO     | __main__:main:1313 - Adding repo to repos_for_merged_dataset
2024-09-12 19:12:15.893 | INFO     | dynamic_database:generate_merged_dataset:415 - Merging selected repositories in the database:
2024-09-12 19:12:15.893 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/dwrensha/compfiles (commit: f99bf6f2928d47dd1a445b414b3a723c2665f091)
2024-09-12 19:12:15.893 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/AlexKontorovich/PrimeNumberTheoremAnd (commit: 29baddd685660b5fedd7bd67f9916ae24253d566)
2024-09-12 19:12:15.893 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/avigad/mathematics_in_lean_source (commit: 5297e0fb051367c48c0a084411853a576389ecf5)
2024-09-12 19:12:15.893 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/yuma-mizuno/lean-math-workshop (commit: 5acd4b933d47fd6c1032798a6046c1baf261445d)
2024-09-12 19:12:15.893 | INFO     | dynamic_database:generate_merged_dataset:417 -   - https://github.com/ImperialCollegeLondon/FLT (commit: b208a302cdcbfadce33d8165f0b054bfa17e2147)
2024-09-12 19:16:34.095 | WARNING  | dynamic_database:safe_remove_dir_path:377 - /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147 already exists. Removing i
t now.
2024-09-12 19:17:09.773 | INFO     | dynamic_database:generate_merged_dataset:439 - Exported proofs to /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147
2024-09-12 19:17:10.773 | INFO     | dynamic_database:generate_merged_dataset:442 - Merged and exported corpus to /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa1
7e2147
2024-09-12 19:17:10.794 | INFO     | dynamic_database:generate_merged_dataset:445 - Exported traced files to /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e214
7
2024-09-12 19:17:10.800 | INFO     | dynamic_database:generate_merged_dataset:448 - Exported metadata to /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147
2024-09-12 19:17:10.837 | INFO     | __main__:main:1327 - All GPUs
2024-09-12 19:17:10.838 | INFO     | __main__:find_latest_checkpoint:524 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a60
46c1baf261445d_lambda_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:17:10.838 | INFO     | __main__:main:1334 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lambda
_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:17:10.838 | INFO     | __main__:main:1340 - Inside train_test_fisher
2024-09-12 19:17:10.838 | INFO     | __main__:main:1341 - Starting training at epoch 4
[rank: 0] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module impli
citly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the defau
lt value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by t
he user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this e
xperimental feature.
2024-09-12 19:17:14.682 | INFO     | __main__:main:1365 - Loaded premise retriever at /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lam
bda_0.1_epoch=3-Recall@10_val=59.21.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/plugins/environments/slurm.py:204: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLUR
M, prepend your python command with `srun` like so: srun python main4.py ...
Using bfloat16 Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
2024-09-12 19:17:14.780 | INFO     | __main__:main:1423 - right before barrier for data module
2024-09-12 19:17:14.780 | INFO     | __main__:main:1438 - Data path: /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be dep
racted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-12 19:17:14.893 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/corpus.jsonl
100%|| 151983/151983 [00:23<00:00, 6390.77it/s]
2024-09-12 19:18:12.550 | INFO     | retrieval.datamodule:load_or_cache_data:65 - Saved loaded data to cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e214
7/random/cache_train/cached_data.pkl
Training dataset size: 411151
100%|| 3166/3166 [00:00<00:00, 5825.42it/s]
2024-09-12 19:18:13.221 | INFO     | retrieval.datamodule:load_or_cache_data:65 - Saved loaded data to cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e214
7/random/cache_val/cached_data.pkl
Validation dataset size: 7123
100%|| 3166/3166 [00:00<00:00, 6818.81it/s]
2024-09-12 19:18:13.797 | INFO     | retrieval.datamodule:load_or_cache_data:65 - Saved loaded data to cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e214
7/random/cache_pred/cached_data.pkl
Testing dataset size: 6437
2024-09-12 19:18:13.797 | INFO     | __main__:main:1452 - Training dataset size after load: 411151
2024-09-12 19:18:13.797 | INFO     | __main__:main:1453 - Validation dataset size after load: 7123
2024-09-12 19:18:13.797 | INFO     | __main__:main:1454 - Testing dataset size after load: 6437
2024-09-12 19:18:13.797 | INFO     | __main__:main:1456 - Starting progressive training from epoch 4 to 5
2024-09-12 19:18:13.797 | INFO     | __main__:main:1459 - hit the barrier before training
[rank: 0] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/4
[2024-09-12 19:18:19,608] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-12 19:18:19,609] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-09-12 19:18:19,611] [INFO] [real_accelerator.py:203:get_accelerator] Setting ds_accelerator to cuda (auto detect)
2024-09-12 19:18:23.596 | INFO     | __main__:main:1205 - Running progressive training
2024-09-12 19:18:23.596 | INFO     | __main__:main:1205 - Running progressive training
2024-09-12 19:18:23.596 | INFO     | __main__:main:1205 - Running progressive training
2024-09-12 19:18:23.596 | INFO     | __main__:main:1211 - Configuring LeanDojo...
2024-09-12 19:18:23.596 | INFO     | __main__:main:1211 - Configuring LeanDojo...
2024-09-12 19:18:23.596 | INFO     | __main__:main:1211 - Configuring LeanDojo...
2024-09-12 19:18:23.599 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-12 19:18:23.599 | INFO     | __main__:main:1213 - LeanDojo configured
2024-09-12 19:18:23.599 | INFO     | __main__:main:1235 - Found 15 repositories
2024-09-12 19:18:23.599 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-12 19:18:23.599 | INFO     | generate_benchmark_lean4:configure_leandojo:347 - Current working directory: /data/yingzi_ma/lean_project/ReProver
2024-09-12 19:18:23.599 | INFO     | __main__:main:1238 - Starting curriculum learning
2024-09-12 19:18:23.599 | INFO     | __main__:main:1213 - LeanDojo configured
2024-09-12 19:18:23.599 | INFO     | __main__:main:1213 - LeanDojo configured
2024-09-12 19:18:23.599 | INFO     | __main__:main:1235 - Found 15 repositories
2024-09-12 19:18:23.599 | INFO     | __main__:main:1235 - Found 15 repositories
2024-09-12 19:18:23.599 | INFO     | __main__:main:1238 - Starting curriculum learning
2024-09-12 19:18:23.599 | INFO     | __main__:main:1238 - Starting curriculum learning
2024-09-12 19:18:24.013 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
2024-09-12 19:18:24.013 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
2024-09-12 19:18:24.013 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc2
2024-09-12 19:18:40.492 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
2024-09-12 19:18:40.515 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
2024-09-12 19:18:40.633 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0-rc1
2024-09-12 19:18:57.224 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0
2024-09-12 19:18:57.224 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0
2024-09-12 19:18:57.224 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0
2024-09-12 19:19:13.712 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0
2024-09-12 19:19:13.712 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0
2024-09-12 19:19:13.870 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.8.0
2024-09-12 19:19:31.003 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0-rc2
2024-09-12 19:19:31.003 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0-rc2
2024-09-12 19:19:31.164 | DEBUG    | lean_dojo.data_extraction.lean:_to_commit_hash:90 - Querying the commit hash for lean4 v4.7.0-rc2
2024-09-12 19:19:48.704 | INFO     | __main__:main:1296 - length of lean_git_repos: 11
2024-09-12 19:19:48.704 | INFO     | __main__:main:1297 - i: 0
2024-09-12 19:19:48.704 | INFO     | __main__:main:1327 - All GPUs
2024-09-12 19:19:48.704 | INFO     | __main__:main:1296 - length of lean_git_repos: 11
2024-09-12 19:19:48.704 | INFO     | __main__:main:1297 - i: 0
2024-09-12 19:19:48.704 | INFO     | __main__:main:1327 - All GPUs
2024-09-12 19:19:48.705 | INFO     | __main__:find_latest_checkpoint:524 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a60
46c1baf261445d_lambda_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:19:48.705 | INFO     | __main__:find_latest_checkpoint:524 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a60
46c1baf261445d_lambda_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:19:48.705 | INFO     | __main__:main:1334 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lambda
_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:19:48.705 | INFO     | __main__:main:1334 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lambda
_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:19:48.705 | INFO     | __main__:main:1340 - Inside train_test_fisher
2024-09-12 19:19:48.705 | INFO     | __main__:main:1340 - Inside train_test_fisher
2024-09-12 19:19:48.705 | INFO     | __main__:main:1341 - Starting training at epoch 4
2024-09-12 19:19:48.705 | INFO     | __main__:main:1341 - Starting training at epoch 4
[rank: 2] Seed set to 3407
[rank: 1] Seed set to 3407
2024-09-12 19:19:48.907 | INFO     | __main__:main:1296 - length of lean_git_repos: 11
2024-09-12 19:19:48.907 | INFO     | __main__:main:1297 - i: 0
2024-09-12 19:19:48.907 | INFO     | __main__:main:1327 - All GPUs
2024-09-12 19:19:48.908 | INFO     | __main__:find_latest_checkpoint:524 - Using the latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a60
46c1baf261445d_lambda_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:19:48.908 | INFO     | __main__:main:1334 - Found latest checkpoint: /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lambda
_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:19:48.908 | INFO     | __main__:main:1340 - Inside train_test_fisher
2024-09-12 19:19:48.908 | INFO     | __main__:main:1341 - Starting training at epoch 4
[rank: 3] Seed set to 3407
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module impli
citly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the defau
lt value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by t
he user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this e
xperimental feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module impli
citly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the defau
lt value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by t
he user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this e
xperimental feature.
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module impli
citly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the defau
lt value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by t
he user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this e
xperimental feature.
2024-09-12 19:19:51.130 | INFO     | __main__:main:1365 - Loaded premise retriever at /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lam
bda_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:19:51.227 | INFO     | __main__:main:1423 - right before barrier for data module
2024-09-12 19:19:51.227 | INFO     | __main__:main:1438 - Data path: /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be dep
racted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-12 19:19:51.331 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/corpus.jsonl
2024-09-12 19:19:51.454 | INFO     | __main__:main:1365 - Loaded premise retriever at /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lam
bda_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:19:51.485 | INFO     | __main__:main:1365 - Loaded premise retriever at /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lam
bda_0.1_epoch=3-Recall@10_val=59.21.ckpt
2024-09-12 19:19:51.500 | INFO     | __main__:main:1423 - right before barrier for data module
2024-09-12 19:19:51.500 | INFO     | __main__:main:1438 - Data path: /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/random
2024-09-12 19:19:51.527 | INFO     | __main__:main:1423 - right before barrier for data module
2024-09-12 19:19:51.527 | INFO     | __main__:main:1438 - Data path: /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/random
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be dep
racted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be dep
racted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884
  warnings.warn(
2024-09-12 19:19:51.650 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/corpus.jsonl
2024-09-12 19:19:51.654 | INFO     | common:__init__:212 - Building the corpus from /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/corpus.jsonl
2024-09-12 19:20:22.317 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_train/cached_data.pkl
Training dataset size: 411151
2024-09-12 19:20:22.360 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_val/cached_data.pkl
Validation dataset size: 7123
2024-09-12 19:20:22.397 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_pred/cached_data.pkl
Testing dataset size: 6437
2024-09-12 19:20:22.398 | INFO     | __main__:main:1452 - Training dataset size after load: 411151
2024-09-12 19:20:22.398 | INFO     | __main__:main:1453 - Validation dataset size after load: 7123
2024-09-12 19:20:22.398 | INFO     | __main__:main:1454 - Testing dataset size after load: 6437
2024-09-12 19:20:22.398 | INFO     | __main__:main:1456 - Starting progressive training from epoch 4 to 5
2024-09-12 19:20:22.398 | INFO     | __main__:main:1459 - hit the barrier before training
[rank: 1] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/4
2024-09-12 19:20:24.717 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_train/cached_data.pkl
Training dataset size: 411151
2024-09-12 19:20:24.755 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_val/cached_data.pkl
Validation dataset size: 7123
2024-09-12 19:20:24.789 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_pred/cached_data.pkl
Testing dataset size: 6437
2024-09-12 19:20:24.789 | INFO     | __main__:main:1452 - Training dataset size after load: 411151
2024-09-12 19:20:24.789 | INFO     | __main__:main:1453 - Validation dataset size after load: 7123
2024-09-12 19:20:24.789 | INFO     | __main__:main:1454 - Testing dataset size after load: 6437
2024-09-12 19:20:24.789 | INFO     | __main__:main:1456 - Starting progressive training from epoch 4 to 5
2024-09-12 19:20:24.789 | INFO     | __main__:main:1459 - hit the barrier before training
[rank: 2] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/4
2024-09-12 19:20:25.069 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_train/cached_data.pkl
Training dataset size: 411151
2024-09-12 19:20:25.106 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_val/cached_data.pkl
Validation dataset size: 7123
2024-09-12 19:20:25.140 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_pred/cached_data.pkl
Testing dataset size: 6437
2024-09-12 19:20:25.140 | INFO     | __main__:main:1452 - Training dataset size after load: 411151
2024-09-12 19:20:25.140 | INFO     | __main__:main:1453 - Validation dataset size after load: 7123
2024-09-12 19:20:25.140 | INFO     | __main__:main:1454 - Testing dataset size after load: 6437
2024-09-12 19:20:25.140 | INFO     | __main__:main:1456 - Starting progressive training from epoch 4 to 5
2024-09-12 19:20:25.140 | INFO     | __main__:main:1459 - hit the barrier before training
[rank: 3] Seed set to 3407
Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/4
----------------------------------------------------------------------------------------------------
distributed_backend=nccl
All distributed processes registered. Starting with 4 processes
----------------------------------------------------------------------------------------------------

NCCL version 2.20.5+cuda12.4
2024-09-12 19:20:30.588 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_train/cached_data.pkl
Training dataset size: 411151
2024-09-12 19:20:31.001 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_val/cached_data.pkl
Validation dataset size: 7123
2024-09-12 19:20:31.093 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_pred/cached_data.pkl
Testing dataset size: 6437
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:653: Checkpoint directory /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum exists and is not emp
ty.
2024-09-12 19:20:41.337 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_train/cached_data.pkl
Training dataset size: 411151
2024-09-12 19:20:41.624 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_val/cached_data.pkl
Validation dataset size: 7123
2024-09-12 19:20:41.641 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_train/cached_data.pkl
2024-09-12 19:20:41.689 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_pred/cached_data.pkl
Testing dataset size: 6437
2024-09-12 19:20:41.796 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_train/cached_data.pkl
Training dataset size: 411151
2024-09-12 19:20:41.920 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_val/cached_data.pkl
Validation dataset size: 7123
2024-09-12 19:20:41.983 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_pred/cached_data.pkl
Testing dataset size: 6437
Training dataset size: 411151
2024-09-12 19:20:42.070 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_val/cached_data.pkl
Validation dataset size: 7123
2024-09-12 19:20:42.130 | INFO     | retrieval.datamodule:load_or_cache_data:52 - Loaded data from cache /data/yingzi_ma/lean_project/datasets_PT_merge_all_no_ewc_curriculum/merged_with_new_FLT_b208a302cdcbfadce33d8165f0b054bfa17e2147/ra
ndom/cache_pred/cached_data.pkl
Testing dataset size: 6437
Restoring states from the checkpoint path at /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lambda_0.1_epoch=3-Recall@10_val=59.21.ckpt
/data/yingzi_ma/miniconda3/envs/ReProver/lib/python3.10/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module impli
citly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the defau
lt value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by t
he user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this e
xperimental feature.
LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]
2024-09-12 19:20:43.644 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-12 19:20:43.644 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-12 19:20:43.644 | INFO     | common:get_optimizers:449 - Optimizing with AdamW
2024-09-12 19:20:43.644 | INFO     | common:get_optimizers:449 - Optimizing with AdamW

  | Name    | Type           | Params
-------------------------------------------
0 | encoder | T5EncoderModel | 217 M
-------------------------------------------
217 M     Trainable params
0         Non-trainable params
217 M     Total params
870.630   Total estimated model params size (MB)
Restored all states from the checkpoint at /data/yingzi_ma/lean_project/checkpoints_PT_merge_all_no_ewc_curriculum/merged_with_new_lean-math-workshop_5acd4b933d47fd6c1032798a6046c1baf261445d_lambda_0.1_epoch=3-Recall@10_val=59.21.ckpt
Epoch 4:   1%|                                                                                                                                                   | 199/25697 [01:1Epoch 4:   1%|                            | 200/25697 [0
1:15<2:40:11,  2.65it/s, v_num=4]                                                                                          Epoch 4:   1%|                            | 200/25697 [EpocEpoch 4:   6%|
                                                                                                            | 1559/25697 [09:35<2:28:29,  2.71it/s, v_Epoch 4:   6%|                          | 1560/25697 [09:35<2:28:29,  2.71it/s, v_num
=4]                                                                                                                      Epoch 4:   7%|                                       | 1874/25697Epoch 4:   7%|                          | 1875
/25697 [11:26<2:25:24,  2.73it/s, v_num=4]Epoch 4:   7%|                          | 1876/25697 [11:2Epoch 4:  61%|                 Epoch 4:  61%|
         | 15755/25697 [1:35:39<1:00:21,  2.75it/s, v_num=4]                                                                                          EpEpoch 4:  63%|               | 16189/25697 [
Epoch 4:  63%|                                                                | 16199/25697 [1:38:24<57:42,  2.74it/s, v_num=4]
